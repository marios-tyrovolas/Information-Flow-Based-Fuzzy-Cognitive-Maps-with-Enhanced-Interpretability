{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install Flask --upgrade\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_friedman3, make_s_curve\n",
    "from sklearn.linear_model import BayesianRidge, ElasticNet\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#!pip install imbalanced-learn\n",
    "#!pip install lightgbm\n",
    "#!pip install wittgenstein --user\n",
    "#!pip install explainerdashboard --user\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# for Box-Cox Transformation\n",
    "from scipy import stats\n",
    "\n",
    "# plotting modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "#Multilabel Stratified K Fold Creation\n",
    "#!pip install iterative-stratification\n",
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0     1                298.1                    308.6                    1551   \n",
       "1     0                298.2                    308.7                    1408   \n",
       "2     0                298.1                    308.5                    1498   \n",
       "3     0                298.2                    308.6                    1433   \n",
       "4     0                298.2                    308.7                    1408   \n",
       "\n",
       "   Torque [Nm]  Tool wear [min]  Machine failure  TWF  HDF  PWF  OSF  RNF  \n",
       "0         42.8                0                0    0    0    0    0    0  \n",
       "1         46.3                3                0    0    0    0    0    0  \n",
       "2         49.4                5                0    0    0    0    0    0  \n",
       "3         39.5                7                0    0    0    0    0    0  \n",
       "4         40.0                9                0    0    0    0    0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collect data from sensors (i.e., time-series data) installed in the manufacturing system \n",
    "ai4i2020_encoded_balanced=pd.read_csv(r'..\\\\..\\\\dataset\\\\raw_data\\\\ai4i2020_encoded_balanced.csv')\n",
    "ai4i2020_encoded_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in local\n",
    "# Fold index\n",
    "fold = 1\n",
    "\n",
    "original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "original_X_test = pd.read_csv('G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "auc_list = []\n",
    "kappa_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Cognitive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "y_train_pred_fcm = genfromtxt(r'..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_pred_fcm.csv\", delimiter=',')\n",
    "y_test_pred_fcm = genfromtxt(r'..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_pred_fcm.csv\", delimiter=',')\n",
    "fcm_pred_class_train = genfromtxt(r'..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\fcm_pred_class_train.csv\", delimiter=',')\n",
    "fcm_pred_class_test = genfromtxt(r'..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\fcm_pred_class_test.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAGdCAYAAACsBCEsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyh0lEQVR4nO3df1yV9f3/8edJ8IQIR1E5x2NqWHxNw6yoEFtp83dDcq1pYWTL/DFLIzSNtS1nG6T7pK5YptammUVtZfVpRtJWlFPUKDY1tfpoKcoRLDyK0QHlfP9oXtu5QLs4HeLoHvfdrtstrut13udNm+vV6/V+vy+b3+/3CwAAoJnOae0JAACAMxNJBAAACApJBAAACApJBAAACApJBAAACApJBAAACApJBAAACApJBAAACApJBAAACEpEa0/gpPpDu1t7CkDYiXJf09pTAMLS8br9LTp+KP+ZFNm5V8jGCjdhk0QAABA2Gk609gzOCLQzAABAUKhEAABg5m9o7RmcEUgiAAAwayCJsIIkAgAAEz+VCEtYEwEAAIJCJQIAADPaGZaQRAAAYEY7wxLaGQAAIChUIgAAMOOwKUtIIgAAMKOdYQntDAAAEBQqEQAAmLE7wxKSCAAATDhsyhraGQAAIChUIgAAMKOdYQlJBAAAZrQzLCGJAADAjHMiLGFNBAAACAqVCAAAzGhnWEISAQCAGQsrLaGdAQAAgkIlAgAAM9oZlpBEAABgRjvDEtoZAAAgKFQiAAAw8fs5J8IKkggAAMxYE2EJ7QwAABAUKhEAAJixsNISkggAAMxoZ1hCEgEAgBkv4LKENREAACAoVCIAADCjnWEJSQQAAGYsrLSEdgYAAAgKlQgAAMxoZ1hCEgEAgBntDEtoZwAAgKBQiQAAwIxKhCUkEQAAmPAWT2toZwAAgKCQRAAAYNbQELqrmfbv369bb71VnTp1Urt27XTppZeqtLTUeO73+zV37ly53W5FRUVp8ODB2r59e8AYPp9P06dPV+fOnRUdHa309HSVl5cHxFRXVyszM1MOh0MOh0OZmZk6fPhws+ZKEgEAgJm/IXRXM1RXV+vqq69WZGSkXn/9dX344Yd65JFH1KFDByNmwYIFWrhwofLz87Vlyxa5XC4NGzZMR48eNWKysrK0Zs0aFRQUaP369aqpqVFaWppOnPh3myYjI0NlZWUqLCxUYWGhysrKlJmZ2az52vx+v79Zn2gh9Yd2t/YUgLAT5b6mtacAhKXjdftbdPzavy4L2VhRQyZbjr3//vv197//Xe+++26Tz/1+v9xut7KysjRnzhxJX1cdnE6n5s+frylTpsjr9apLly5atWqVxo0bJ0k6cOCAunfvrrVr12rEiBHasWOH+vbtq5KSEqWkpEiSSkpKlJqaqp07d6p3796W5kslAgCAFuTz+XTkyJGAy+fzNRn76quv6oorrtCPf/xjxcfH67LLLtPy5cuN53v27JHH49Hw4cONe3a7XYMGDdKGDRskSaWlpaqvrw+IcbvdSkpKMmI2btwoh8NhJBCSNGDAADkcDiPGCpIIAADMQtjOyMvLM9YdnLzy8vKa/Nrdu3dryZIlSkxM1BtvvKGpU6dqxowZevrppyVJHo9HkuR0OgM+53Q6jWcej0dt27ZVx44dTxsTHx/f6Pvj4+ONGCvY4gkAgFkIz4nIyclRdnZ2wD273X6Kr23QFVdcodzcXEnSZZddpu3bt2vJkiW67bbbjDibzRbwOb/f3+iemTmmqXgr4/wnKhEAALQgu92u2NjYgOtUSUTXrl3Vt2/fgHt9+vTR3r17JUkul0uSGlULKisrjeqEy+VSXV2dqqurTxtz8ODBRt9fVVXVqMpxOiQRAACYtdLujKuvvlq7du0KuPfRRx+pZ8+ekqSEhAS5XC4VFRUZz+vq6lRcXKyBAwdKkpKTkxUZGRkQU1FRoW3bthkxqamp8nq92rx5sxGzadMmeb1eI8YK2hkAAJi10rHX9957rwYOHKjc3FyNHTtWmzdv1rJly7Rs2de7RWw2m7KyspSbm6vExEQlJiYqNzdX7dq1U0ZGhiTJ4XBo4sSJmjlzpjp16qS4uDjNmjVL/fr109ChQyV9Xd0YOXKkJk2apKVLl0qSJk+erLS0NMs7MySSCAAAwsaVV16pNWvWKCcnR/PmzVNCQoIWL16s8ePHGzGzZ89WbW2tpk2bpurqaqWkpGjdunWKiYkxYhYtWqSIiAiNHTtWtbW1GjJkiFasWKE2bdoYMatXr9aMGTOMXRzp6enKz89v1nw5JwIIY5wTATStxc+J+MvikI0V9YOskI0VbqhEAABg1sy1DP+tWFgJAACCQiUCAACzVlpYeaYhiQAAwIx2hiUkEQAAmFGJsIQ1EQAAIChUIgAAMKOdYQlJBAAAZrQzLKGdAQAAgkIlAgAAMyoRlpBEAABgFh5vhAh7tDMAAEBQqEQAAGBGO8MSkggAAMxIIiyhnQEAAIJCJQIAADMOm7KEJAIAADPaGZaQRAAAYMYWT0tYEwEAAIJCJQIAADPaGZaQRAAAYEYSYQntDAAAEBQqEQAAmLHF0xKSCAAATPwN7M6wgnYGAAAICpUIAADMWFhpCUkEAABmrImwhHYGAAAICpUIAADMWFhpCUkEAABmrImwhCQCAAAzkghLWBMBAACCQiUCAAAzXgVuCUnEWehg1SEtfPwPWl/ynny+OvXs3k3zcrJ08UWJkqSkq0c1+bnsaRN1x/ibJEm33z1b732wNeD5yCHX6n/m5Rg/f7q3XI/8/il9sPVD1dfXK/GCBM2YdJuuSu7fQr8ZEDqffFSi88/v3uj+40tWaMY9D+ipJxdpwm1jA55t2vS+rr5mtPHzX4v+pEGDBgbEPP/CKxp/67SWmTS+O7QzLCGJOMt4jxxV5tSZuury/nrikYcU17GD9u0/oJj20UbM26+uDvjMuyXv6Zd5izVs8NUB929KH6m778w0frbb7QHPp933oHp276anHn1Y59rbatULL+uu2Q/q9Rf+oM6d4lrgtwNCZ8DA69WmTRvj56SLL9IbhQV68cXXjHuFhX/TxEnZxs91dfWNxln+5DOa+6v/MX6urf2qhWYMhB+SiLPMH1b/Sa74Lvr1A//+P75uXZ0BMeZ/wL/1bomuuvwSde/WNeD+uXb7KZOB6sNe7S0/oIdy7lXvCxMkSfdO/YkKXnpNn+z5jCQCYe/QoS8Cfp5939365JM9Kn5no3HPV1engwerTjvOl19+9Y0xOAOxxdMSFlaeZd5aX6KLL0pU9s9/o2t/cLNuuv0u/fnV108Zf+iLar2zYbNuTBvR6Nlfit7S964fpxvGT9Fv85fr2LEvjWcdHLHqdX53vVr4V31Z+5WOHz+hF15Zq05xHdW3d2KL/G5AS4mMjNT4jBu1YuXzAfcHXZuqA+X/0Ifb39UTSxaoS5dOjT6bccsP5TmwVf8o+5sWPPwLtf+Pqh/OYP6G0F1nsWZXIsrLy7VkyRJt2LBBHo9HNptNTqdTAwcO1NSpU9W9e+MeI7475Qc8ev7lv+i2cTdq0m3jtPXDj5S36AlFRkbqhlFDG8W/+vqbatcuSkMHBbYy0oZfp25dXercqaM+3v2pfvfECu36eI+e/F2uJMlms2n54lxNnzNPKcNu1Dnn2NSpY0ctfeQhxca0/05+VyBUbrhhpDp0iNXKp18w7hW+8ZZefPE1fba3XAnn99DcufepaN0LuipllOrq6iRJzz63Rp9+uk+eg5W6+OLe+s1DObrkkr4aef0trfWrAN8pm99vfQnq+vXrNWrUKHXv3l3Dhw+X0+mU3+9XZWWlioqKtG/fPr3++uu6+uqrTzuOz+eTz+cLuHfO0f2Neu5ovksHjdbFFyVq9dKFxr3cRUu0fcdHWr1sUaP40bdMUuqVl+ln2adfCLZ958caN3GGXvjDY+rb+0L5/X7NuH+ejh8/rkkTbta5drte/N9Cvb2+RAVPPqounWlnhEKU+5rWnsJ/hbWvrVZdfb3G/PD2U8a4XPHa/ckmZdw6TS+/3HR17/LL+mnzpkJdedUIfVC2rYVmC0k6Xre/Rcf/cv5PQjZWuzl/DNlY4aZZlYh7771Xd955pxYtavwPo5PPs7KytGXLltOOk5eXp1/96lcB935+3wz9cvY9zZkOmtClU5wuOL9HwL1e53fXm2//vVFsadk27dlbrt/+x46LU+nb+0JFRETos3371bf3hdpUWqbiDZu1ofAFtY+O/lfM3dq45QO98vqbujNz7DeMCISHHj26aciQa3TT2DtPG+fxVOqzz/Yr8V9rgJry/gdbVVdXpwsTe5FEnOH87M6wpFlrIrZt26apU6ee8vmUKVO0bds3/8HJycmR1+sNuObcc+pxYd1ll/TVp3vLA+59tne/urriG8W+9Nob6ts7URcl9vrGcT/Z85mOHz9uVBi++urrStI5tsD/CZ1js6mBP3w4g9w+YZwqKw9p7dq/njYuLq6junfvqgpP5SljLr64t9q2bStPxcFQTxMIS81KIrp27aoNGzac8vnGjRvVtWvXUz4/yW63KzY2NuCilREamePG6J/bd2rZygLtLT+gv6x7S39+9XXdcmNaQFzNsWNa99a7+tHoxgsq95Yf0JI/rNa2HR9pf8VBvbNhs7J/nqs+/+8CXdavrySpf1Ifxca0189+/Yh2frxbn+4t1//kP6nyioO6duBV38nvCnxbNptNE24bp1XP/EknTpww7kdHt9OCh3+hASnJ6tnzPA26NlWvrFmhQ4eqjVZGr1499fMHspR8+SXq2fM8jRr5fRU8t1Tvf7BVf99w+moszgAN/tBdZ7FmtTNmzZqlqVOnqrS0VMOGDZPT6ZTNZpPH41FRUZGefPJJLV68uIWmCiv69emtxXm/0O+eWKEnVjyrbl1dmnPPFKWN+H5A3OtvFsvvl64fNrjRGJGRkdpUWqZn/vSKvqytlSu+i64deJWm3THe2FffsYNDTzzykB5dtlITZ9yv48eP68KEnnrs4V9aqmwA4WDokGvUs+d5+uOKwF0ZJ040KCnpIt16603q0CFWFRWVert4g24Z/1PV1ByT9PWZEd+/7nuafvedat++nfbtO6C1r/9VD/16EdW4s8FZvqsiVJq1sFKSnn/+eS1atEilpaVG5t6mTRslJycrOztbY8cG1wuvP7Q7qM8BZzMWVgJNa+mFlcfmjQ/ZWNG/XP3NQWeoZm/xHDdunMaNG6f6+nodOnRIktS5c2dFRkaGfHIAACB8BX1iZWRkpKX1DwAAnHFoSVnCsdcAAJid5QsiQ4VjrwEAQFCoRAAAYMbuDEtIIgAAMKOdYQntDAAAEBSSCAAATPwNDSG7mmPu3Lmy2WwBl8vl+ve8/H7NnTtXbrdbUVFRGjx4sLZv3x4whs/n0/Tp09W5c2dFR0crPT1d5eWBr0Oorq5WZmamHA6HHA6HMjMzdfjw4Wb/fSKJAADArBWPvb744otVUVFhXFu3bjWeLViwQAsXLlR+fr62bNkil8ulYcOG6ejRo0ZMVlaW1qxZo4KCAq1fv141NTVKS0sLONo9IyNDZWVlKiwsVGFhocrKypSZmdnsubImAgCAMBIRERFQfTjJ7/dr8eLFeuCBB3TjjTdKklauXCmn06lnn31WU6ZMkdfr1VNPPaVVq1Zp6NChkqRnnnlG3bt315tvvqkRI0Zox44dKiwsVElJiVJSUiRJy5cvV2pqqnbt2qXevXtbniuVCAAAzEJYifD5fDpy5EjA5fP5TvnVH3/8sdxutxISEnTzzTdr9+6vXwuxZ88eeTweDR8+3Ii12+0aNGiQ8XLM0tJS1dfXB8S43W4lJSUZMRs3bpTD4TASCEkaMGCAHA7HaV+y2RSSCAAAzPwNIbvy8vKMtQcnr7y8vCa/NiUlRU8//bTeeOMNLV++XB6PRwMHDtTnn38uj8cjSXI6nQGfcTqdxjOPx6O2bduqY8eOp42Jj49v9N3x8fFGjFW0MwAAMAvhFs+cnBxlZ2cH3LPb7U3Gjho1yvjrfv36KTU1VRdccIFWrlypAQMGSPr6Ffb/ye/3N7pnZo5pKt7KOGZUIgAAaEF2u12xsbEB16mSCLPo6Gj169dPH3/8sbFOwlwtqKysNKoTLpdLdXV1qq6uPm3MwYMHG31XVVVVoyrHNyGJAADAxN/gD9n1bfh8Pu3YsUNdu3ZVQkKCXC6XioqKjOd1dXUqLi7WwIEDJUnJycmKjIwMiKmoqNC2bduMmNTUVHm9Xm3evNmI2bRpk7xerxFjFe0MAADMWunEylmzZmn06NHq0aOHKisr9etf/1pHjhzRhAkTZLPZlJWVpdzcXCUmJioxMVG5ublq166dMjIyJEkOh0MTJ07UzJkz1alTJ8XFxWnWrFnq16+fsVujT58+GjlypCZNmqSlS5dKkiZPnqy0tLRm7cyQSCIAAAgb5eXluuWWW3To0CF16dJFAwYMUElJiXr27ClJmj17tmprazVt2jRVV1crJSVF69atU0xMjDHGokWLFBERobFjx6q2tlZDhgzRihUr1KZNGyNm9erVmjFjhrGLIz09Xfn5+c2er83v94fFAeH1h3a39hSAsBPlvqa1pwCEpeN1+1t0/KN3Xx+ysWLy14ZsrHBDJQIAADNewGUJCysBAEBQqEQAAGBGJcISkggAAEzCZLlg2KOdAQAAgkIlAgAAM9oZlpBEAABgRhJhCUkEAAAm3/a46v8WrIkAAABBoRIBAIAZlQhLSCIAADBraO0JnBloZwAAgKBQiQAAwISFldaQRAAAYEYSYQntDAAAEBQqEQAAmLGw0hKSCAAATFgTYQ3tDAAAEBQqEQAAmNHOsIQkAgAAE9oZ1pBEAABgRiXCEtZEAACAoFCJAADAxE8lwhKSCAAAzEgiLKGdAQAAgkIlAgAAE9oZ1pBEAABgRhJhCe0MAAAQFCoRAACY0M6whiQCAAATkghrSCIAADAhibCGNREAACAoVCIAADDz21p7BmcEkggAAExoZ1hDOwMAAASFSgQAACb+BtoZVpBEAABgQjvDGtoZAAAgKFQiAAAw8bM7wxKSCAAATGhnWEM7AwAABIVKBAAAJuzOsIYkAgAAE7+/tWdwZiCJAADAhEqENayJAAAAQaESAQCACZUIa0giAAAwYU2ENbQzAABAUKhEAABgQjvDGpIIAABMOPbaGtoZAACEoby8PNlsNmVlZRn3/H6/5s6dK7fbraioKA0ePFjbt28P+JzP59P06dPVuXNnRUdHKz09XeXl5QEx1dXVyszMlMPhkMPhUGZmpg4fPtzsOZJEAABg4m8I3RWMLVu2aNmyZbrkkksC7i9YsEALFy5Ufn6+tmzZIpfLpWHDhuno0aNGTFZWltasWaOCggKtX79eNTU1SktL04kTJ4yYjIwMlZWVqbCwUIWFhSorK1NmZmaz50kSAQCASYPfFrKruWpqajR+/HgtX75cHTt2NO77/X4tXrxYDzzwgG688UYlJSVp5cqV+vLLL/Xss89Kkrxer5566ik98sgjGjp0qC677DI988wz2rp1q958801J0o4dO1RYWKgnn3xSqampSk1N1fLly/Xaa69p165dzZorSQQAAC3I5/PpyJEjAZfP5ztl/F133aUf/OAHGjp0aMD9PXv2yOPxaPjw4cY9u92uQYMGacOGDZKk0tJS1dfXB8S43W4lJSUZMRs3bpTD4VBKSooRM2DAADkcDiPGKpIIAABM/H5byK68vDxj7cHJKy8vr8nvLSgo0Pvvv9/kc4/HI0lyOp0B951Op/HM4/Gobdu2ARWMpmLi4+MbjR8fH2/EWMXuDAAATEK5xTMnJ0fZ2dkB9+x2e6O4ffv26Z577tG6det07rnnnnI8my1wbn6/v9E9M3NMU/FWxjGjEgEAgInfH7rLbrcrNjY24GoqiSgtLVVlZaWSk5MVERGhiIgIFRcX69FHH1VERIRRgTBXCyorK41nLpdLdXV1qq6uPm3MwYMHG31/VVVVoyrHNyGJAAAgDAwZMkRbt25VWVmZcV1xxRUaP368ysrK1KtXL7lcLhUVFRmfqaurU3FxsQYOHChJSk5OVmRkZEBMRUWFtm3bZsSkpqbK6/Vq8+bNRsymTZvk9XqNGKtoZwAAYNIaJ1bGxMQoKSkp4F50dLQ6depk3M/KylJubq4SExOVmJio3NxctWvXThkZGZIkh8OhiRMnaubMmerUqZPi4uI0a9Ys9evXz1io2adPH40cOVKTJk3S0qVLJUmTJ09WWlqaevfu3aw5k0QAAGASzNbM78Ls2bNVW1uradOmqbq6WikpKVq3bp1iYmKMmEWLFikiIkJjx45VbW2thgwZohUrVqhNmzZGzOrVqzVjxgxjF0d6erry8/ObPR+b3x8e7yqrP7S7tacAhJ0o9zWtPQUgLB2v29+i42/rlRaysZJ2vxayscINlQgAAEx4d4Y1JBEAAJiER40+/LE7AwAABIVKBAAAJuG6sDLckEQAAGDCmghraGcAAICgUIkAAMCEhZXWkEQAAGDCmghrwiaJGHv5Pa09BSDs1Pz90daeAvBfiTUR1rAmAgAABCVsKhEAAIQL2hnWkEQAAGDCukpraGcAAICgUIkAAMCEdoY1JBEAAJiwO8Ma2hkAACAoVCIAADBpaO0JnCFIIgAAMPGLdoYVtDMAAEBQqEQAAGDSwEERlpBEAABg0kA7wxKSCAAATFgTYQ1rIgAAQFCoRAAAYMIWT2tIIgAAMKGdYQ3tDAAAEBQqEQAAmNDOsIYkAgAAE5IIa2hnAACAoFCJAADAhIWV1pBEAABg0kAOYQntDAAAEBQqEQAAmPDuDGtIIgAAMOElntaQRAAAYMIWT2tYEwEAAIJCJQIAAJMGG2sirCCJAADAhDUR1tDOAAAAQaESAQCACQsrrSGJAADAhBMrraGdAQAAgkIlAgAAE06stIYkAgAAE3ZnWEM7AwAABIVKBAAAJiystIYkAgAAE7Z4WkMSAQCACWsirGFNBAAACAqVCAAATFgTYQ1JBAAAJqyJsIZ2BgAAYWLJkiW65JJLFBsbq9jYWKWmpur11183nvv9fs2dO1dut1tRUVEaPHiwtm/fHjCGz+fT9OnT1blzZ0VHRys9PV3l5eUBMdXV1crMzJTD4ZDD4VBmZqYOHz7c7PmSRAAAYNIQwqs5zjvvPD388MN677339N577+n73/++brjhBiNRWLBggRYuXKj8/Hxt2bJFLpdLw4YN09GjR40xsrKytGbNGhUUFGj9+vWqqalRWlqaTpw4YcRkZGSorKxMhYWFKiwsVFlZmTIzM5v998nm9/vDYhHqD3uMbu0pAGHnuRdvb+0pAGHp3Ct/1KLjP9H91pCNNXXfM9/q83Fxcfrtb3+rO+64Q263W1lZWZozZ46kr6sOTqdT8+fP15QpU+T1etWlSxetWrVK48aNkyQdOHBA3bt319q1azVixAjt2LFDffv2VUlJiVJSUiRJJSUlSk1N1c6dO9W7d2/Lc6MSAQBAC/L5fDpy5EjA5fP5vvFzJ06cUEFBgY4dO6bU1FTt2bNHHo9Hw4cPN2LsdrsGDRqkDRs2SJJKS0tVX18fEON2u5WUlGTEbNy4UQ6Hw0ggJGnAgAFyOBxGjFUkEQAAmISynZGXl2esPTh55eXlnfK7t27dqvbt28tut2vq1Klas2aN+vbtK4/HI0lyOp0B8U6n03jm8XjUtm1bdezY8bQx8fHxjb43Pj7eiLGK3RkAAJiEcndGTk6OsrOzA+7Z7fZTxvfu3VtlZWU6fPiwXnzxRU2YMEHFxcXGc5stcP+p3+9vdM/MHNNUvJVxzKhEAADQgux2u7Hb4uR1uiSibdu2uvDCC3XFFVcoLy9P/fv31+9+9zu5XC5JalQtqKysNKoTLpdLdXV1qq6uPm3MwYMHG31vVVVVoyrHNyGJAADAxB/C61vPxe+Xz+dTQkKCXC6XioqKjGd1dXUqLi7WwIEDJUnJycmKjIwMiKmoqNC2bduMmNTUVHm9Xm3evNmI2bRpk7xerxFjFe0MAABMWuvEyp/97GcaNWqUunfvrqNHj6qgoEBvv/22CgsLZbPZlJWVpdzcXCUmJioxMVG5ublq166dMjIyJEkOh0MTJ07UzJkz1alTJ8XFxWnWrFnq16+fhg4dKknq06ePRo4cqUmTJmnp0qWSpMmTJystLa1ZOzMkkggAABpprRMrDx48qMzMTFVUVMjhcOiSSy5RYWGhhg0bJkmaPXu2amtrNW3aNFVXVyslJUXr1q1TTEyMMcaiRYsUERGhsWPHqra2VkOGDNGKFSvUpk0bI2b16tWaMWOGsYsjPT1d+fn5zZ4v50QAYYxzIoCmtfQ5EYt6hO6ciHv3frtzIsIZlQgAAEx4d4Y1JBEAAJiERYn+DMDuDAAAEBQqEQAAmLTW7owzDUkEAAAmrImwhnYGAAAICpUIAABMWFhpDUkEAAAmDaQRltDOAAAAQaESAQCACQsrrSGJAADAhGaGNSQRAACYUImwhjURAAAgKFQiAAAw4cRKa0giAAAwYYunNbQzAABAUKhEAABgQh3CGpIIAABM2J1hDe0MAAAQFCoRAACYsLDSGpIIAABMSCGsoZ0BAACCQiUCAAATFlZaQxIBAIAJayKsIYkAAMCEFMIa1kQAAICgUIkAAMCENRHWkEQAAGDip6FhCe0MAAAQFCoRAACY0M6whiQCAAATtnhaQzsDAAAEhUoEAAAm1CGsIYk4y9x4100aMHKgzrugm+q+qtPO0p16Om+FDuzeHxA37t5bNDxjhKId7fXxBx9p2S+e0L6P9hrPh2WM0LU3DFKvpAvULqadxifdrC+PHAsYI9oRrTt/NUVXDr1KkrTlzc1a/suljeKAcHHwC68WF7yhv/9zl3x1x9XT1VlzJ92ovgndVH/8hPL/XKT1ZbtUXvWFYqLOVUrShbpn3AjFd4w1xpj31Bpt2v5/qqo+onbntlX/xJ7KunmEEtzxRsyMR57Wrr0V+uLIMcW2i1JK0gXKunlkwDgIb7QzrKGdcZa5OCVJr6/8i+aMuU9zx/9CbSLa6MFn5skeZTdifvjTHyn9zjFa/oulmp2Wreqqas1dPU/nRkcZMfYouz4ofl8v/v5Pp/yu7EfvU0LfBD1024N66LYHldA3QVmLs1v09wOCdeRYrW6ft1QRbc7R7++7XS/Nz9LMjFGKaXeuJOmrunrt/PSAJo+5Ts8/dLcWZo3XZxWHdM/CVQHj9E3opnmTf6Q1C+7Vktk/kd/v19T5f9SJhn8vxbuyby/9dvoteuW39+qRezJUXvmFZj367Hf6+wLfBSoRZ5mHbpsb8PNjMxdrZdlqXdDvQn24ebskKW1iuv6c/4JKCjdKkh7NXqQVpat07ZhBWre6UJL02lOvSpIuHpDU5Pecd+F5uvy6ZM1On6mPyz6SJD0+J1/zX/kfuXt1a1T5AFrbH/63WM44hx6acpNxr1uXjsZfx7Q7V0vvvyPgM/ffNlrjH3xcFYcOq2vnDpKkm75/VcDn7/7xMP34Z4/pQFW1ujs7SZIyR33PiHF37qg70gYpa/Ezqj9+QpERbVri10OIsTvDGioRZ7l2MdGSpJrDRyVJzh5OxcXHqeydD4yY43XHtX3TNl2UfJHlcXtffpGOeWuMBEKSPvpgl455a5o1DvBdKX5/hy7udZ5mPfqsBk/7jcY+8JhefGvLaT9TU/uVbDabUa0w+/KrOr3yzvvq1qWjXJ0cTcZ4a77UXzaUqX9iDxKIM4g/hP85m1GJOMv95JcT9eHm7dr7r/UOHf71b16HDx0OiDt86LC6dIs3f/yUOnTpKO/n3kb3vZ971SG+YxOfAFpXeVW1XvjrJmWOvFoT0wdr2//t0/yn/1dtI9po9DWXN4r31dXrd8+/oVGp/dXelEQ8X1SiRQWFqvXVKcHdRUvvv0OREYH/d7qooFAFRRv1la9el1zYXY/NnNCivx9Ci0qENSGvROzbt0933HHHaWN8Pp+OHDkScJ3wnwj1VP7rTX5oqs6/6HwtvPu3jR/6A7Njm80mv795GXOT8TYby5oRlhoa/Opzvlszxo1Qn/Pd+vGQFN143ZV64a+bGsXWHz+hOb8vUEODXw/cnt7o+fVXX6rnf3O3/vDzSerh7KT7HntOvrr6gJjbf3CNnv/1dD0x5yc655xz9PMn/tTsP2NAuAt5EvHFF19o5cqVp43Jy8uTw+EIuD468kmop/Jf7c5fTdaVw67SL25+QJ97PjfuH66qlvTvisRJjk4OeU3VidM5XFWtDv/qEQeMExdrfAcQTrp0iFEvd2C1rZe7iypMFbX64yd032PPaX9VtZbef0ejKoT09fqJnq7OSr4oQY/ck6E9FVX623sfBsR0jInW+V07K7VfohbcdbPe/ccu/fOTfaH/xdAiaGdY0+x2xquvvnra57t37/7GMXJycpSdHbiK/9aLb27uVHAKk+ZNUcrIVP1ibI4q9x0MeHZw70F9UfmF+l9zqfZs//q/q4jICF2ckqSnHz598vefdr2/U9GO9krsn6iP//GxJCnx0v+naEd77SzdGbpfBgiRS/9fD31aURVw7zPP53L/RzJ8MoHYe/CQnvzZneoQ087a4H6p7vjx0zz++h8kdfWnjkF4oZ1hTbOTiDFjxnxj6dtms512DLvdLrvdHnCvjY0FR6Ew+dc/1bU3XKu8O3+j2mO16tClgyTpyyNfqs5XJ+nrnRc33fVjVew5oIo9B/Sju8fK95VP77xcbIzToUsHdejSUV3Pd0uSel7UU7U1tTq0v0o13hqVf1Ku998q1U/nT9cTOb+XJP304bu05c3N7MxAWLp15Pc0Yd4TevKVtzU8pZ+27d6nP7+1Wb+844eSpOMnTmjWo89qx6cH9NjM29TQ4Nehfy1IdrSPUmREhMorv9AbJf9Uar9EdYyJVmX1Ef3xtWLZ20boe/17S5K2/t8+bfu/cl3Wu6dio6NUXvmFHv/zm+oeH6f+iT1a7fcHWoLN38wmXbdu3fT73/9eY8aMafJ5WVmZkpOTdeJE89Y4/LDH6GbFo2lr9v5vk/cfzV6st/78V+PncffeouHjR6p9bHt9XPaRlv18ibH48uTzm+/NOO047R3t/9U2SZEkbSnapGUcNhVSz714e2tP4axS/MFOPfr8G9p78HN169JRmaO+px9dd6UkaX9Vta6/t4n1Q5Ke/NmdurJvL1VWH9GvnnxJH+7ZryPHvlInR3slX3S+poz5vs53d5EkfbzPo/mrXtNHeytU66tX5w4xuvqSRE264To545rewYHmO/fKH7Xo+Jk9bwzZWKs+eylkY4WbZicR6enpuvTSSzVv3rwmn//jH//QZZddpoaG5hWDSCKAxkgigKa1dBJxawiTiGfO4iSi2e2M++67T8eOnfrfNC+88EK99dZb32pSAAAg/DU7ibjmmmtO+zw6OlqDBg0KekIAALQ23p1hDYdNAQBgcrZvzQwVjr0GAABBoRIBAIAJ50RYQxIBAIAJayKsoZ0BAIBJax17nZeXpyuvvFIxMTGKj4/XmDFjtGvXrsC5+f2aO3eu3G63oqKiNHjwYG3fvj0gxufzafr06ercubOio6OVnp6u8vLygJjq6mplZmYar5/IzMzU4cOHmzVfkggAAMJEcXGx7rrrLpWUlKioqEjHjx/X8OHDA45WWLBggRYuXKj8/Hxt2bJFLpdLw4YN09GjR42YrKwsrVmzRgUFBVq/fr1qamqUlpYWcBBkRkaGysrKVFhYqMLCQpWVlSkzM7NZ8232YVMthcOmgMY4bApoWksfNnVjz8Zvbw3WS5+d/p1Tp1NVVaX4+HgVFxfr2muvld/vl9vtVlZWlubMmSPp66qD0+nU/PnzNWXKFHm9XnXp0kWrVq3SuHHjJEkHDhxQ9+7dtXbtWo0YMUI7duxQ3759VVJSopSUr08dLikpUWpqqnbu3KnevXtbmh+VCAAATPx+f8iub8Pr/fots3FxcZKkPXv2yOPxaPjw4UaM3W7XoEGDtGHDBklSaWmp6uvrA2LcbreSkpKMmI0bN8rhcBgJhCQNGDBADofDiLGChZUAALQgn88nn88XcK+pF1Ga+f1+ZWdn63vf+56SkpIkSR6PR5LkdDoDYp1Opz777DMjpm3bturYsWOjmJOf93g8io+Pb/Sd8fHxRowVVCIAADBpkD9kV15enrF48eSVl5f3jXO4++679c9//lPPPfdco2fmt2X7/f5vfIO2OaapeCvj/CeSCAAATBpCeOXk5Mjr9QZcOTk5p/3+6dOn69VXX9Vbb72l8847z7jvcrkkqVG1oLKy0qhOuFwu1dXVqbq6+rQxBw8ebPS9VVVVjaocp0MSAQBAC7Lb7YqNjQ24TtXK8Pv9uvvuu/XSSy/pb3/7mxISEgKeJyQkyOVyqaioyLhXV1en4uJiDRw4UJKUnJysyMjIgJiKigpt27bNiElNTZXX69XmzZuNmE2bNsnr9RoxVrAmAgAAk9Z6d8Zdd92lZ599Vq+88opiYmKMioPD4VBUVJRsNpuysrKUm5urxMREJSYmKjc3V+3atVNGRoYRO3HiRM2cOVOdOnVSXFycZs2apX79+mno0KGSpD59+mjkyJGaNGmSli5dKkmaPHmy0tLSLO/MkEgiAABopLVOrFyyZIkkafDgwQH3//jHP+r222+XJM2ePVu1tbWaNm2aqqurlZKSonXr1ikmJsaIX7RokSIiIjR27FjV1tZqyJAhWrFihdq0aWPErF69WjNmzDB2caSnpys/P79Z8+WcCCCMcU4E0LSWPifi+h7Xh2ystXvXhmyscEMlAgAAkzD59+uwRxIBAIAJb/G0hiQCAACT1lpYeaZhiycAAAgKlQgAAExaa3fGmYYkAgAAExZWWkM7AwAABIVKBAAAJrQzrCGJAADAhN0Z1tDOAAAAQaESAQCASQMLKy0hiQAAwIQUwhraGQAAIChUIgAAMGF3hjUkEQAAmJBEWEMSAQCACSdWWsOaCAAAEBQqEQAAmNDOsIYkAgAAE06stIZ2BgAACAqVCAAATFhYaQ1JBAAAJqyJsIZ2BgAACAqVCAAATGhnWEMSAQCACe0Ma2hnAACAoFCJAADAhHMirCGJAADApIE1EZaQRAAAYEIlwhrWRAAAgKBQiQAAwIR2hjUkEQAAmNDOsIZ2BgAACAqVCAAATGhnWEMSAQCACe0Ma2hnAACAoFCJAADAhHaGNSQRAACY0M6whnYGAAAICpUIAABM/P6G1p7CGYEkAgAAkwbaGZaQRAAAYOJnYaUlrIkAAABBoRIBAIAJ7QxrSCIAADChnWEN7QwAABAUKhEAAJhwYqU1JBEAAJhwYqU1tDMAAEBQqEQAAGDCwkprSCIAADBhi6c1tDMAAAgT77zzjkaPHi232y2bzaaXX3454Lnf79fcuXPldrsVFRWlwYMHa/v27QExPp9P06dPV+fOnRUdHa309HSVl5cHxFRXVyszM1MOh0MOh0OZmZk6fPhws+dLEgEAgInf7w/Z1RzHjh1T//79lZ+f3+TzBQsWaOHChcrPz9eWLVvkcrk0bNgwHT161IjJysrSmjVrVFBQoPXr16umpkZpaWk6ceKEEZORkaGysjIVFhaqsLBQZWVlyszMbPbfJ5s/TBo/P+wxurWnAISd5168vbWnAISlc6/8UYuOHxeTGLKxvjj6cVCfs9lsWrNmjcaMGSPp68TG7XYrKytLc+bMkfR11cHpdGr+/PmaMmWKvF6vunTpolWrVmncuHGSpAMHDqh79+5au3atRowYoR07dqhv374qKSlRSkqKJKmkpESpqanauXOnevfubXmOVCIAADAJZSXC5/PpyJEjAZfP52v2nPbs2SOPx6Phw4cb9+x2uwYNGqQNGzZIkkpLS1VfXx8Q43a7lZSUZMRs3LhRDofDSCAkacCAAXI4HEaMVSQRAAC0oLy8PGPtwckrLy+v2eN4PB5JktPpDLjvdDqNZx6PR23btlXHjh1PGxMfH99o/Pj4eCPGKnZnAABgEsrdGTk5OcrOzg64Z7fbgx7PZrMF/Oz3+xvdMzPHNBVvZRwzKhEAAJiEsp1ht9sVGxsbcAWTRLhcLklqVC2orKw0qhMul0t1dXWqrq4+bczBgwcbjV9VVdWoyvFNSCIAADgDJCQkyOVyqaioyLhXV1en4uJiDRw4UJKUnJysyMjIgJiKigpt27bNiElNTZXX69XmzZuNmE2bNsnr9RoxVtHOAADApLVewFVTU6NPPvnE+HnPnj0qKytTXFycevTooaysLOXm5ioxMVGJiYnKzc1Vu3btlJGRIUlyOByaOHGiZs6cqU6dOikuLk6zZs1Sv379NHToUElSnz59NHLkSE2aNElLly6VJE2ePFlpaWnN2pkhkUQAANBIa72A67333tN1111n/HxyLcWECRO0YsUKzZ49W7W1tZo2bZqqq6uVkpKidevWKSYmxvjMokWLFBERobFjx6q2tlZDhgzRihUr1KZNGyNm9erVmjFjhrGLIz09/ZRnU5wO50QAYYxzIoCmtfQ5EdHtzg/ZWMe+/DRkY4UbKhEAAJi0VjvjTEMSAQCASZgU6cMeuzMAAEBQqEQAAGDSWgsrzzQkEQAAmNDOsIYkAgAAE5IIa1gTAQAAgkIlAgAAE+oQ1oTNYVMIDz6fT3l5ecrJyflWb5kDzib8uQCaRhKBAEeOHJHD4ZDX61VsbGxrTwcIC/y5AJrGmggAABAUkggAABAUkggAABAUkggEsNvtevDBB1k8BvwH/lwATWNhJQAACAqVCAAAEBSSCAAAEBSSCAAAEBSSCAAAEBSSCBgef/xxJSQk6Nxzz1VycrLefffd1p4S0KreeecdjR49Wm63WzabTS+//HJrTwkIKyQRkCQ9//zzysrK0gMPPKAPPvhA11xzjUaNGqW9e/e29tSAVnPs2DH1799f+fn5rT0VICyxxROSpJSUFF1++eVasmSJca9Pnz4aM2aM8vLyWnFmQHiw2Wxas2aNxowZ09pTAcIGlQiorq5OpaWlGj58eMD94cOHa8OGDa00KwBAuCOJgA4dOqQTJ07I6XQG3Hc6nfJ4PK00KwBAuCOJgMFmswX87Pf7G90DAOAkkgioc+fOatOmTaOqQ2VlZaPqBAAAJ5FEQG3btlVycrKKiooC7hcVFWngwIGtNCsAQLiLaO0JIDxkZ2crMzNTV1xxhVJTU7Vs2TLt3btXU6dObe2pAa2mpqZGn3zyifHznj17VFZWpri4OPXo0aMVZwaEB7Z4wvD4449rwYIFqqioUFJSkhYtWqRrr722tacFtJq3335b1113XaP7EyZM0IoVK777CQFhhiQCAAAEhTURAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKCQRAAAgKP8flZACW48/jNkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, fcm_pred_class_train)\n",
    "sns.heatmap(confusion_matrix(y_train, fcm_pred_class_train), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.8919576416714368\n",
      "Recall Score:  0.7561567390513163\n",
      "F1 Score:  0.8184623465301032\n",
      "Accuracy Score:  0.8245112972835745\n"
     ]
    }
   ],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,fcm_pred_class_train))\n",
    "print(\"Recall Score: \",recall_score(y_train, fcm_pred_class_train))\n",
    "print(\"F1 Score: \",f1_score(y_train, fcm_pred_class_train))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, fcm_pred_class_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.8835534213685474\n",
      "Recall Score:  0.8034934497816594\n",
      "F1 Score:  0.8416237850200115\n",
      "Accuracy Score:  0.8418046830382638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, fcm_pred_class_test))\n",
    "print(\"Recall Score: \",recall_score(y_test, fcm_pred_class_test))\n",
    "print(\"F1 Score: \",f1_score(y_test, fcm_pred_class_test))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, fcm_pred_class_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755667703893523\n"
     ]
    }
   ],
   "source": [
    "#calculate AUC of model\n",
    "from sklearn import metrics\n",
    "auc_fcm = metrics.roc_auc_score(y_test, y_test_pred_fcm)\n",
    "print(auc_fcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6843182597727349"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_score_fcm = cohen_kappa_score(y_test, fcm_pred_class_test)\n",
    "cohen_score_fcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(metrics.accuracy_score(y_test, fcm_pred_class_test))\n",
    "auc_list.append(auc_fcm)\n",
    "kappa_list.append(cohen_score_fcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable Boosting Machine (EBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default parameters were used, as suggested by the library originators [6,11] and also to specifically assess how well the algorithm performed “out-of-box”. Specifically, 5000 rounds of boosting were used with a learning rate of 0.01. We obtained all graphics representing the one-dimensional feature functions for each predictor variable, two-dimensional feature functions for included interactions, and global importance estimates based on mean absolute scores. We also explored local predictions for selected points.\n",
    "\n",
    "6. Nori, H.; Jenkins, S.; Koch, P.; Caruana, R. InterpretML: A Unified Framework for Machine Learning Interpretability. arXiv 2019, arXiv:1909.09223. [Google Scholar]\n",
    "\n",
    "11. Nori, H.; Caruana, R.; Bu, Z.; Shen, J.H.; Kulkarni, J. Accuracy, Interpretability, and Differential Privacy via Explainable Boosting. arXiv 2021, arXiv:2106.09680. [Google Scholar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExplainableBoostingClassifier(random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExplainableBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>ExplainableBoostingClassifier(random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExplainableBoostingClassifier(random_state=50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "seed = 50\n",
    "ebm = ExplainableBoostingClassifier(random_state=seed)\n",
    "\n",
    "ebm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping_rounds': 50,\n",
       " 'early_stopping_tolerance': 0.0001,\n",
       " 'exclude': [],\n",
       " 'feature_names': None,\n",
       " 'feature_types': None,\n",
       " 'greediness': 0.0,\n",
       " 'inner_bags': 0,\n",
       " 'interactions': 10,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_bins': 256,\n",
       " 'max_interaction_bins': 32,\n",
       " 'max_leaves': 3,\n",
       " 'max_rounds': 5000,\n",
       " 'min_samples_leaf': 2,\n",
       " 'n_jobs': -2,\n",
       " 'objective': 'log_loss',\n",
       " 'outer_bags': 8,\n",
       " 'random_state': 50,\n",
       " 'smoothing_rounds': 0,\n",
       " 'validation_size': 0.15}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainable Boosting Machine score:  0.9980959634424981\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_ebm = ebm.predict(X_train)\n",
    "\n",
    "print(\"Explainable Boosting Machine score: \",ebm.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_ebm)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_ebm), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.9974560872198668\n",
      "Recall Score:  0.9989081645032148\n",
      "F1 Score:  0.9981815977694265\n",
      "Accuracy Score:  0.9980959634424981\n"
     ]
    }
   ],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,y_train_pred_ebm))\n",
    "print(\"Recall Score: \",recall_score(y_train,y_train_pred_ebm))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_ebm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train,y_train_pred_ebm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.9848975188781014\n",
      "Recall Score:  0.9967248908296943\n",
      "F1 Score:  0.9907759088442756\n",
      "Accuracy Score:  0.9902912621359223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_ebm = ebm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_ebm))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_ebm))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_ebm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_ebm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9899792118819131\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_ebm = metrics.roc_auc_score(y_test, y_test_pred_ebm)\n",
    "print(auc_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_ebm = cohen_kappa_score(y_test, y_test_pred_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_ebm))\n",
    "auc_list.append(auc_ebm)\n",
    "kappa_list.append(cohen_score_ebm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/2871402212096/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/2871402212096/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/2871428943584/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/2871428943584/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test, y_test)\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "import lightgbm as lgb\n",
    "lgbmc_clf = lgb.LGBMClassifier()\n",
    "lgbmc_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier score:  0.9996826605737497\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_lgbmc = lgbmc_clf.predict(X_train)\n",
    "\n",
    "print(\"LightGBM Classifier score: \",lgbmc_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_lgbmc)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_lgbmc), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.9996360989810772\n",
      "Recall Score:  0.9997573698896033\n",
      "F1 Score:  0.9996967307575666\n",
      "Accuracy Score:  0.9996826605737497\n"
     ]
    }
   ],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,y_train_pred_lgbmc))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_lgbmc))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_lgbmc))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_lgbmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lgb=lgb.LGBMClassifier()\n",
    "#Define the parameters\n",
    "parameters = {'num_leaves':[20,40,60,80,100], 'min_child_samples':[5,10,15],'max_depth':[-1,5,10,20],\n",
    "             'learning_rate':[0.05,0.1,0.2],'reg_alpha':[0,0.01,0.03]}\n",
    "\n",
    "#Define the scoring\n",
    "grid_search_lgbmc_clf=GridSearchCV(lgb,parameters,scoring='accuracy')\n",
    "grid_search_lgbmc_clf.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(grid_search_lgbmc_clf.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lgbmc_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_lgbmc = grid_search_lgbmc_clf.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_lgbmc))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_lgbmc))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_lgbmc))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_lgbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_lgbmc = metrics.roc_auc_score(y_test, y_test_pred_lgbmc)\n",
    "print(auc_lgbmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_lgbmc = cohen_kappa_score(y_test, y_test_pred_lgbmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_lgbmc))\n",
    "auc_list.append(auc_lgbmc)\n",
    "kappa_list.append(cohen_score_lgbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIPPER\n",
    "The Ripper method is a classification algorithm based on rules. The training set is used to generate a set of rules. It’s a common rule-induction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wittgenstein as lw\n",
    "ripper_clf = lw.RIPPER() # Or irep_clf = lw.IREP() to build a model using IREP\n",
    "ripper_clf.fit(X_train, y_train.values.ravel()) # Or pass X and y data to .fit\n",
    "ripper_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts positive class if any of the inner-nested condition-combinations are all true.  The word that you will often see that indicates a union is \"or\" and intersection is \"and\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ripper_clf.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_train_pred_ripper = ripper_clf.predict(X_train)\n",
    "\n",
    "#Default scoring metric is accuracy.\n",
    "accuracy = ripper_clf.score(X_train,  y_train.values.ravel())\n",
    "precision = ripper_clf.score(X_train,  y_train.values.ravel())\n",
    "recall = ripper_clf.score(X_train,  y_train.values.ravel())\n",
    "cond_count = ripper_clf.ruleset_.count_conds()\n",
    "print(f'accuracy: {accuracy} precision: {precision} recall: {recall} conds: {cond_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_ripper)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_ripper), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning for RIPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_ripper = {\"prune_size\": [0.33, 0.5], \"k\": [1, 2]}\n",
    "grid_ripper = GridSearchCV(estimator=lw.RIPPER(), param_grid=param_grid_ripper)\n",
    "grid_ripper.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(grid_ripper.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ripper.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_test_pred_ripper = grid_ripper.best_estimator_.predict(X_test)\n",
    "\n",
    "#Default scoring metric is accuracy.\n",
    "accuracy = grid_ripper.best_estimator_.score(X_test,  y_test.values.ravel())\n",
    "precision = grid_ripper.best_estimator_.score(X_test, y_test.values.ravel(), precision_score)\n",
    "recall = grid_ripper.best_estimator_.score(X_test, y_test.values.ravel(), recall_score)\n",
    "cond_count = grid_ripper.best_estimator_.ruleset_.count_conds()\n",
    "print(f'accuracy: {accuracy} precision: {precision} recall: {recall} conds: {cond_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_ripper = metrics.roc_auc_score(y_test, y_test_pred_ripper)\n",
    "print(auc_ripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_ripper = cohen_kappa_score(y_test, y_test_pred_ripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy)\n",
    "auc_list.append(auc_ripper)\n",
    "kappa_list.append(cohen_score_ripper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask our model to tell us why it made each positive prediction that it did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ripper.best_estimator_.predict(X_test, give_reasons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "give_reasons = grid_ripper.best_estimator_.predict(X_test, give_reasons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "give_reasons[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_knn = knn.predict(X_train)\n",
    "\n",
    "print(\"K-Nearest Neighbour score: \",knn.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_knn)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_knn), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,y_train_pred_knn))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_knn))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_knn))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning for K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "grid_search_knn = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "\n",
    "grid_search_knn.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(grid_search_knn.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_knn = grid_search_knn.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_knn))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_knn))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_knn))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_knn = metrics.roc_auc_score(y_test, y_test_pred_knn)\n",
    "print(auc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_knn = cohen_kappa_score(y_test, y_test_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_knn))\n",
    "auc_list.append(auc_knn)\n",
    "kappa_list.append(cohen_score_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dt_clf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_dt = dt_clf.predict(X_train)\n",
    "\n",
    "print(\"Decision Tree score: \",dt_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_dt)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_dt), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,y_train_pred_dt))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_dt))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_dt))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=dt_clf, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(grid_search.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_dt = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_dt))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_dt))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_dt))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_dt = metrics.roc_auc_score(y_test, y_test_pred_dt)\n",
    "print(auc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_dt = cohen_kappa_score(y_test, y_test_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_dt))\n",
    "auc_list.append(auc_dt)\n",
    "kappa_list.append(cohen_score_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(50,100,50),\n",
    "                        max_iter = 300,activation = 'relu',\n",
    "                        solver = 'adam')\n",
    "\n",
    "mlp_clf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mlp_clf.loss_curve_)\n",
    "plt.title(\"Loss Curve\", fontsize=14)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_mlp_clf = mlp_clf.predict(X_train)\n",
    "\n",
    "print(\"MLPClassifier score: \",mlp_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_mlp_clf)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_mlp_clf), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,y_train_pred_mlp_clf))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_mlp_clf))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_mlp_clf))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_mlp_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "mlp = MLPClassifier(max_iter=300)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_test_pred_mlp_clf = clf.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_mlp_clf))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_mlp_clf))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_mlp_clf))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_mlp_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_test_pred_mlp_clf)) # order matters! (actual, predicted)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred_mlp_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate AUC of model\n",
    "from sklearn import metrics\n",
    "auc_ann = metrics.roc_auc_score(y_test, y_test_pred_mlp_clf)\n",
    "print(auc_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_ann = cohen_kappa_score(y_test, y_test_pred_mlp_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(metrics.accuracy_score(y_test, y_test_pred_mlp_clf))\n",
    "auc_list.append(metrics.roc_auc_score(y_test, y_test_pred_mlp_clf))\n",
    "kappa_list.append(cohen_score_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "svm_clf = svm.SVC(kernel='linear',probability=True) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_svm = svm_clf.predict(X_train)\n",
    "\n",
    "print(\"Support Vector Machine score: \",svm_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_svm)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_svm), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_svm))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_svm))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_svm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning for Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "rnd_search_svm = GridSearchCV(svm_clf,param_grid,refit=True,verbose=2)\n",
    "rnd_search_svm.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_svm.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_svm = rnd_search_svm.best_estimator_.predict(X_test)\n",
    "#y_test_pred_sgd = sgd_clf.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_svm))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_svm))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_svm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_svm = metrics.roc_auc_score(y_test, y_test_pred_svm)\n",
    "print(auc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_svm = cohen_kappa_score(y_test, y_test_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_svm))\n",
    "auc_list.append(auc_svm)\n",
    "kappa_list.append(cohen_score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_nb = nb_clf.predict(X_train)\n",
    "\n",
    "print(\"Naive Bayes score: \",nb_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_nb)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_nb), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_nb))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_nb))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_nb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning for Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "NB_distribution = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "nb_clf = GaussianNB()       \n",
    "\n",
    "rnd_search_nb = RandomizedSearchCV(nb_clf, param_distributions = NB_distribution, random_state = 42) \n",
    "rnd_search_nb.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_nb.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "#y_test_pred_nb = nb_clf.predict(X_test)\n",
    "y_test_pred_nb = rnd_search_nb.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_nb))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_nb))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_nb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate AUC of model\n",
    "from sklearn import metrics\n",
    "auc_nb = metrics.roc_auc_score(y_test, y_test_pred_nb)\n",
    "print(auc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_nb = cohen_kappa_score(y_test, y_test_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_nb))\n",
    "auc_list.append(auc_nb)\n",
    "kappa_list.append(cohen_score_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_sgd = sgd_clf.predict(X_train)\n",
    "print(\"Stochastic Gradient Descent Classifier score: \",sgd_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_sgd)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_sgd), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_sgd))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_sgd))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_sgd))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "param_distribs = {\n",
    "        \"average\": [True, False],\n",
    "        \"loss\":['hinge', 'log_loss', 'modified_huber', 'squared_hinge',  'perceptron'],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        \"learning_rate\":['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        \"class_weight\":[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "        \"eta0\":[1, 10, 100],\n",
    "        \"penalty\":['l2', 'l1', 'elasticnet']\n",
    "    }\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "rnd_search_SGD = RandomizedSearchCV(sgd_clf, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "rnd_search_SGD.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_SGD.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_SGD.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_sgd = rnd_search_SGD.best_estimator_.predict(X_test)\n",
    "#y_test_pred_sgd = sgd_clf.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_sgd))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_sgd))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_sgd))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_sgd = metrics.roc_auc_score(y_test, y_test_pred_sgd)\n",
    "print(auc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_sgd = cohen_kappa_score(y_test, y_test_pred_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_sgd))\n",
    "auc_list.append(auc_sgd)\n",
    "kappa_list.append(cohen_score_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#logistic regression for targets \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_clf = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=42)\n",
    "log_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_log = log_clf.predict(X_train)\n",
    "print(\"Logistic Regression score: \",log_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confusion_matrix(y_train, y_train_pred_log)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_log), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_log))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_log))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_log))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=42)\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2'],\n",
    "                     solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "rnd_search_LR = RandomizedSearchCV(logistic, distributions, random_state=42)\n",
    "rnd_search_LR.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_LR.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnd_search_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_log = rnd_search_LR.best_estimator_.predict(X_test)\n",
    "#y_test_pred_log = log_clf.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_log))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_log))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_log))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_test_pred_log)\n",
    "#calculate AUC of model\n",
    "auc_log = metrics.roc_auc_score(y_test, y_test_pred_log)\n",
    "print(auc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_log = cohen_kappa_score(y_test, y_test_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_log))\n",
    "auc_list.append(auc_log)\n",
    "kappa_list.append(cohen_score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get importance of each feature\n",
    "w0 = rnd_search_LR.best_estimator_.intercept_[0]\n",
    "w = w1, w2, w3, w4, w5, w6 = rnd_search_LR.best_estimator_.coef_[0]\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "feature_importance = pd.DataFrame(feature_names, columns = [\"feature\"])\n",
    "feature_importance[\"importance\"] = pow(math.e,w)\n",
    "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ax = feature_importance.plot.barh(x='feature', y = 'importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "X_train.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_xgb = xgb_classifier.predict(X_train)\n",
    "print(\"XGBoost score: \",xgb_classifier.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confusion_matrix(y_train, y_train_pred_xgb)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_xgb), annot=True,fmt='d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_xgb))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_xgb))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_xgb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "XG_distributions = dict(n_estimators=[100,200,300,400,500,600,700,800, 900, 1000],\n",
    "                     max_depths = [2, 5, 10, 20],\n",
    "                     learning_rate=[0.1,0.15,0.2,0.25,0.3],\n",
    "                     colsample_bytree=[0.5,0.6,0.7,0.8,0.9,1],\n",
    "                     subsample=[0.5,0.6,0.7,0.8,0.9,1],\n",
    "                     grow_policy = ['depthwise', 'lossguide'],\n",
    "                     booster = ['gbtree', 'gblinear', 'dart'],\n",
    "                     sampling_method = ['uniform','gradient_based'])\n",
    "rnd_search_XG = RandomizedSearchCV(xgb_classifier, XG_distributions, random_state=42)\n",
    "rnd_search_XG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_XG.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnd_search_XG.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "X_test.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_xgb = rnd_search_XG.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_pred_xgb), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for test dataset\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score \n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_xgb))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_xgb))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_xgb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_test_pred_xgb)\n",
    "#calculate AUC of model\n",
    "auc_xgb = metrics.roc_auc_score(y_test, y_test_pred_xgb)\n",
    "print(auc_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_score_xgb = cohen_kappa_score(y_test, y_test_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_xgb))\n",
    "auc_list.append(auc_xgb)\n",
    "kappa_list.append(cohen_score_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw ROC curve and PR curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "fpr_FCM, tpr_FCM, thresholds_FCM = roc_curve(y_train, y_train_pred_fcm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Explainable Boosting Machine\n",
    "fpr_EBM, tpr_EBM, thresholds_EBM= roc_curve(y_train, y_train_pred_ebm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#LightGBM Classifier\n",
    "fpr_LGBM, tpr_LGBM, thresholds_LGBM = roc_curve(y_train, y_train_pred_lgbmc)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#RIPPER (Repeated Incremental Pruning to Produce Error Reduction)\n",
    "fpr_RIPPER, tpr_RIPPER, thresholds_RIPPER = roc_curve(y_train, y_train_pred_ripper)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "fpr_DT, tpr_DT, thresholds_DT = roc_curve(y_train, y_train_pred_dt)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#K-Nearest Neighbour (KNN)\n",
    "fpr_KNN, tpr_KNN, thresholds_KNN = roc_curve(y_train, y_train_pred_knn)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#MLP Classifier\n",
    "fpr_MLP, tpr_MLP, thresholds_MLP = roc_curve(y_train, y_train_pred_mlp_clf)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "fpr_SVM, tpr_SVM, thresholds_SVM = roc_curve(y_train,  y_train_pred_svm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "fpr_SGD, tpr_SGD, thresholds_SGD = roc_curve(y_train, y_train_pred_sgd)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "fpr_NB, tpr_NB, thresholds_NB = roc_curve(y_train, y_train_pred_nb)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "fpr_LR, tpr_LR, thresholds_LR = roc_curve(y_train, y_train_pred_log)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "fpr_XG, tpr_XG, thresholds_XG = roc_curve(y_train, y_train_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))              \n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "plt.plot(fpr_FCM, tpr_FCM, linewidth=2, label=\"Fuzzy Cognitive Map\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Explainable Boosting Machine\n",
    "plt.plot(fpr_EBM, tpr_EBM, linewidth=2, label=\"EBM\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#LightGBM Classifier\n",
    "plt.plot(fpr_LGBM, tpr_LGBM, linewidth=2, label=\"LightGBM\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#RIPPER (Repeated Incremental Pruning to Produce Error Reduction)\n",
    "plt.plot(fpr_RIPPER, tpr_RIPPER, linewidth=2, label=\"RIPPER\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#K-Nearest Neighbour (KNN)\n",
    "plt.plot(fpr_KNN, tpr_KNN, linewidth=2, label=\"K-Nearest Neighbour\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "plt.plot(fpr_DT, tpr_DT, linewidth=2, label=\"Decision Tree\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#MLP Classifier\n",
    "plt.plot(fpr_MLP, tpr_MLP, linewidth=2, label=\"MLP Classifier\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "plt.plot(fpr_SVM, tpr_SVM, linewidth=2, label=\"Support Vector Machine\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "plt.plot(fpr_SGD, tpr_SGD, linewidth=2, label=\"Stochastic Gradient Descent\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "plt.plot(fpr_NB, tpr_NB, \"m-\", linewidth=2, label=\"Gaussian Naive Bayes\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "plt.plot(fpr_LR, tpr_LR, linewidth=2, label=\"Logistic Regression\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "plt.plot(fpr_XG, tpr_XG, linewidth=2, label=\"XGBoost\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# fpr_SGD_90 = fpr_SGD[np.argmax(tpr_SGD >= 0.9)]           \n",
    "\n",
    "# plt.plot([fpr_SGD_90, fpr_SGD_90], [0., 0.9], \"r:\")\n",
    "# plt.plot([0.0, fpr_SGD_90], [0.9, 0.9], \"r:\")  \n",
    "# plt.plot([fpr_SGD_90], [0.9], \"ro\")   \n",
    "\n",
    "# AUC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "fpr_FCM, tpr_FCM, thresholds_FCM = roc_curve(y_test, y_test_pred_fcm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Explainable Boosting Machine\n",
    "fpr_EBM, tpr_EBM, thresholds_EBM = roc_curve(y_test, y_test_pred_ebm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#LightGBM Classifier\n",
    "fpr_LGBM, tpr_LGBM, thresholds_LGBM = roc_curve(y_test, y_test_pred_lgbmc)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#RIPPER (Repeated Incremental Pruning to Produce Error Reduction)\n",
    "fpr_RIPPER, tpr_RIPPER, thresholds_RIPPER = roc_curve(y_test, y_test_pred_ripper)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#K-Nearest Neighbour (KNN)\n",
    "fpr_KNN, tpr_KNN, thresholds_KNN = roc_curve(y_test, y_test_pred_knn)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "fpr_DT, tpr_DT, thresholds_DT = roc_curve(y_test, y_test_pred_dt)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#MLP Classifier\n",
    "fpr_MLP, tpr_MLP, thresholds_MLP = roc_curve(y_test, y_test_pred_mlp_clf)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "fpr_SVM, tpr_SVM, thresholds_SVM = roc_curve(y_test, y_test_pred_svm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "fpr_SGD, tpr_SGD, thresholds_SGD = roc_curve(y_test, y_test_pred_sgd)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "fpr_NB, tpr_NB, thresholds_NB = roc_curve(y_test, y_test_pred_nb)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "fpr_LR, tpr_LR, thresholds_LR = roc_curve(y_test, y_test_pred_log)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "fpr_XG, tpr_XG, thresholds_XG = roc_curve(y_test, y_test_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))                                    \n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "plt.plot(fpr_FCM, tpr_FCM, linewidth=2, label=\"Fuzzy Cognitive Map\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Explainable Boosting Machine\n",
    "plt.plot(fpr_EBM, tpr_EBM, linewidth=2, label=\"EBM\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#LightGBM Classifier\n",
    "plt.plot(fpr_LGBM, tpr_LGBM, linewidth=2, label=\"LightGBM\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#RIPPER (Repeated Incremental Pruning to Produce Error Reduction)\n",
    "plt.plot(fpr_RIPPER, tpr_RIPPER, linewidth=2, label=\"RIPPER\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#K-Nearest Neighbour (KNN)\n",
    "plt.plot(fpr_KNN, tpr_KNN, linewidth=2, label=\"K-Nearest Neighbour\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "plt.plot(fpr_DT, tpr_DT, linewidth=2, label=\"Decision Tree\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#MLP Classifier\n",
    "plt.plot(fpr_MLP, tpr_MLP, linewidth=2, label=\"MLP Classifier\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "plt.plot(fpr_SVM, tpr_SVM, linewidth=2, label=\"Support Vector Machine\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "plt.plot(fpr_SGD, tpr_SGD, linewidth=2, label=\"Stochastic Gradient Descent\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "plt.plot(fpr_NB, tpr_NB, \"m-\", linewidth=2, label=\"Gaussian Naive Bayes\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "plt.plot(fpr_LR, tpr_LR, linewidth=2, label=\"Logistic Regression\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "plt.plot(fpr_XG, tpr_XG, linewidth=2, label=\"XGBoost\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# fpr_SGD_90 = fpr_SGD[np.argmax(tpr_SGD >= 0.9)]           \n",
    "\n",
    "# plt.plot([fpr_SGD_90, fpr_SGD_90], [0., 0.9], \"r:\")\n",
    "# plt.plot([0.0, fpr_SGD_90], [0.9, 0.9], \"r:\")  \n",
    "# plt.plot([fpr_SGD_90], [0.9], \"ro\")   \n",
    "\n",
    "# AUC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The area under curve (AUC)\n",
    "Through AUC you can summarize the performance of each classifier into a single measure when comparing different classifiers. Calculating the area under the ROC curve, abbreviated as AUC, is a typical method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_list = ['IF-FCM', 'LightGBM', 'RIPPER', 'K-Nearest Neighbour' ,'Decision Tree', 'MLP Classifier', 'Support Vector Machine', 'Stochastic Gradient Descent', 'Gaussian Naive Bayes', 'Logistic Regression', 'XGBoost']\n",
    "\n",
    "#accuracy and AUC\n",
    "result_df = pd.DataFrame({'Model':model_list, 'Accuracy': acc_list, 'AUC': auc_list, 'Kappa':kappa_list})\n",
    "final_df = result_df.sort_values(by=['AUC'], ascending=False)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Feature Out (LOFO)\n",
    "LOFO first evaluates the performance of the model with all the input features included, then iteratively removes one feature at a time, retrains the model, and evaluates its performance on a validation set. The mean and standard deviation (across the folds) of the importance of each feature is then reported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lofo-importance\n",
    "concat_df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "\n",
    "# define the validation scheme\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# set target\n",
    "target = \"Machine failure\"\n",
    "\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=concat_df, target=target, features=[col for col in concat_df.columns if col != target])\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\" , model=grid_search_lgbmc_clf.best_estimator_)\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()\n",
    "\n",
    "#Save global feature importance for each model\n",
    "#importance_df.to_csv('Global_Feat_Import_ML_mdl\\\\xgb.csv')\n",
    "\n",
    "# plot the means and standard deviations of the importances\n",
    "plot_importance(importance_df, figsize=(12, 20), kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glob_feat_imp_mean_ml=pd.read_csv(r\"Global_Feat_Import_ML_mdl\\\\gl_ft_imp_mn.csv\")\n",
    "glob_feat_imp_std_ml=pd.read_csv(r\"Global_Feat_Import_ML_mdl\\\\glob_feat_imp_std_ml.csv\")\n",
    "\n",
    "model = glob_feat_imp_mean_ml[\"Model\"].tolist()\n",
    "\n",
    "#Mean error\n",
    "toolwear_mean_err = glob_feat_imp_mean_ml[\"Toolwearmin\"].tolist()\n",
    "torque_mean_err = glob_feat_imp_mean_ml[\"TorqueNm\"].tolist()\n",
    "pr_type_mean_err = glob_feat_imp_mean_ml[\"Type\"].tolist()\n",
    "airtemperature_mean_err = glob_feat_imp_mean_ml[\"AirtemperatureK\"].tolist()\n",
    "processtemperature_mean_err = glob_feat_imp_mean_ml[\"ProcesstemperatureK\"].tolist()\n",
    "rotationalspeedrpm_mean_err = glob_feat_imp_mean_ml[\"Rotationalspeedrpm\"].tolist()\n",
    "\n",
    "#Standard deviation\n",
    "toolwear_std = glob_feat_imp_std_ml[\"Toolwearmin\"].tolist()\n",
    "torque_std = glob_feat_imp_std_ml[\"TorqueNm\"].tolist()\n",
    "pr_typer_std = glob_feat_imp_std_ml[\"Type\"].tolist()\n",
    "airtemperaturer_std = glob_feat_imp_std_ml[\"AirtemperatureK\"].tolist()\n",
    "processtemperaturer_std = glob_feat_imp_std_ml[\"ProcesstemperatureK\"].tolist()\n",
    "rotationalspeedrpmr_std = glob_feat_imp_std_ml[\"Rotationalspeedrpm\"].tolist()\n",
    "\n",
    " \n",
    "# Initialise the spider plot by setting figure size and polar projection\n",
    "plt.figure(figsize=(14, 10))\n",
    "axes =plt.subplot(polar=True)\n",
    "axes.spines['polar'].set_visible(False)\n",
    "axes.set_yticklabels([])\n",
    "\n",
    "theta = np.linspace(0, 2 * np.pi, len(toolwear_mean_err))\n",
    " \n",
    "# Arrange the grid into number of sales equal parts in degrees\n",
    "lines, labels = plt.thetagrids(range(0, 360, int(360/len(model))), (model))\n",
    " \n",
    "# Plot actual sales graph\n",
    "#plt.plot(theta, toolwear_mean_err)\n",
    "plt.errorbar(theta, toolwear_mean_err, yerr=toolwear_std, fmt='.C1')\n",
    "plt.fill(theta, toolwear_mean_err, 'C1', alpha=0.2)\n",
    "\n",
    "# Plot expected sales graph\n",
    "#plt.plot(theta, torque_mean_err)\n",
    "plt.errorbar(theta, torque_mean_err, yerr=torque_std, fmt='.g')\n",
    "plt.fill(theta, torque_mean_err, 'g', alpha=0.2)\n",
    "\n",
    "# Plot expected sales graph\n",
    "#plt.plot(theta, pr_type_mean_err)\n",
    "plt.errorbar(theta, pr_type_mean_err, yerr=pr_typer_std, fmt='.r')\n",
    "plt.fill(theta, pr_type_mean_err, 'r', alpha=0.3)\n",
    "\n",
    "# Plot expected sales graph\n",
    "#plt.plot(theta, airtemperature_mean_err)\n",
    "plt.errorbar(theta, airtemperature_mean_err, yerr=airtemperaturer_std, fmt='.k')\n",
    "plt.fill(theta, airtemperature_mean_err, 'p', alpha=0.4)\n",
    "\n",
    "# Plot expected sales graph\n",
    "#plt.plot(theta, processtemperature_mean_err)\n",
    "plt.errorbar(theta, processtemperature_mean_err, yerr=processtemperaturer_std, fmt='.m')\n",
    "plt.fill(theta, processtemperature_mean_err, 'm', alpha=0.5)\n",
    "\n",
    "\n",
    "# Plot expected sales graph\n",
    "#plt.plot(theta, rotationalspeedrpm_mean_err)\n",
    "plt.errorbar(theta, rotationalspeedrpm_mean_err, yerr=rotationalspeedrpmr_std, fmt='.k')\n",
    "plt.fill(theta, rotationalspeedrpm_mean_err, 'k', alpha=0.6)\n",
    "\n",
    "# Add legend and title for the plot\n",
    "plt.legend(labels=('Tool wear', 'Torque', 'Type', 'Air Temperature', 'Process Temperature', 'Rotational Speed'), loc=(0, 1.05), mode='expand',ncol=3)\n",
    " \n",
    "# Dsiplay the plot on the screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Explainability using Permutation Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eli5 --user\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "  \n",
    "# create permutation importance object using model\n",
    "# and fit on test set\n",
    "perm = PermutationImportance(rnd_search_XG.best_estimator_, random_state=1).fit(X_test, y_test.values.ravel())\n",
    "  \n",
    "# display weights using PermutationImportance object\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Explanations"
   ]
  },
  {
   "attachments": {
    "2022-12-31_185323.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2022-12-31_185323.png](attachment:2022-12-31_185323.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper, since we want to evaluate the model's root cause analysis capabilities, we focus only on feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Different models:\n",
    "#fcm: fcm_pred_class_test\n",
    "#lgbmc_clf: y_test_pred_lgbmc\n",
    "#ripper_clf: See the model's explanations in RIPPER cells \n",
    "#knn: y_test_pred_knn\n",
    "#dt_clf: y_test_pred_dt\n",
    "#MLP: y_test_pred_mlp_clf\n",
    "#svm_clf: y_test_pred_svm\n",
    "#rnd_search_nb.best_estimator_: y_test_pred_nb\n",
    "#rnd_search_SGD.best_estimator_: y_test_pred_sgd\n",
    "#rnd_search_LR.best_estimator_: y_test_pred_log\n",
    "#rnd_search_XG.best_estimator_:  y_test_pred_xgb\n",
    "\n",
    "#Find the observations' indexes that the model correctly predicted as faulty\n",
    "#y: Expected values of the model's output\n",
    "y=y_test;\n",
    "true_positive_indexes = []\n",
    "i=1;\n",
    "\n",
    "#According to the chosen model\n",
    "#For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "for k in range(0,len(y)):\n",
    "    if (y.loc[k,'Machine failure']==int(y_test_pred_svm[k])) and (y.loc[k,'Machine failure']==1):\n",
    "        true_positive_indexes.append(k)\n",
    "        i=i+1;\n",
    "\n",
    "        \n",
    "#Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "true_positive_observations = pd.DataFrame()\n",
    "for k in range(0,len(true_positive_indexes)):\n",
    "    new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y.loc[true_positive_indexes[k],:]], axis=0)\n",
    "    true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "\n",
    "    \n",
    "#Find the observations that the selected model correctly predicted correctly as faulty along with the failure modes\n",
    "\n",
    "true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "#for index1 in range(0,len(true_positive_observations)):\n",
    "    #for index2 in range (0,len(ai4i2020_encoded_balanced)):\n",
    "        #if true_positive_observations.loc[index1,:].equals(ai4i2020_encoded_balanced.loc[index2,\"Type\":\"Machine failure\"]) == True:\n",
    "            #print(index1)\n",
    "            #true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.append(ai4i2020_encoded_balanced.loc[index2,:], ignore_index=True)\n",
    "true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]','Machine failure']), ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]','Machine failure'], how='right')       \n",
    "final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "\n",
    "display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "        number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "        number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "        number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "        number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "    if (final_true_positive_observations_with_failure_modes.loc[k,\"Machine failure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "        number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "\n",
    "display(\"Number of TWF failures: \" + str(number_of_TWF_failures_in_true_positive_predictions))\n",
    "display(\"Number of HDF failures: \" + str(number_of_HDF_failures_in_true_positive_predictions))\n",
    "display(\"Number of PWF failures: \" + str(number_of_PWF_failures_in_true_positive_predictions))\n",
    "display(\"Number of OSF failures: \" + str(number_of_OSF_failures_in_true_positive_predictions))\n",
    "display(\"Number of RNF failures: \" + str(number_of_random_failures_in_true_positive_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Interacitve Widget in order to see each true positive observation along with the failure modes\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Output\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "text = widgets.Text()\n",
    "display(text)\n",
    "\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        index = int(text.value)\n",
    "        print(final_true_positive_observations_with_failure_modes.loc[index,:])\n",
    "        print('\\n')\n",
    "        print(\"Dataset index for the above true positive observation (starting from 0 index): \" + str(true_positive_indexes[index]))\n",
    "        \n",
    "text.on_submit(handle_submit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TWF: The tool is replaced or fails after a random **Tool wear**\n",
    "* HDF: If the **temperature** differential between the **air** and the **process** is less than 8.6 K while at the same time the tool's **rotational speed** is less than 1380 rpm\n",
    "* PWF: If the product of **torque** and **rotational speed** in rad/sis less than 3500 W or greater than 9000 W\n",
    "* OSF: The product of **tool wear**, and **torque**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "from explainerdashboard.datasets import titanic_survive, titanic_names\n",
    "from explainerdashboard import InlineExplainer\n",
    "import shap\n",
    "\n",
    "#If you want to explore the entire dashboard \n",
    "#ExplainerDashboard(ClassifierExplainer(lgbmc_clf.fit(X_train, y_train.values.ravel()), X_test, y_test)).run()\n",
    "\n",
    "#Different models:\n",
    "#fcm: fcm_pred_class_test\n",
    "#lgbmc_clf: grid_search_lgbmc_clf.best_estimator_.fit(X_train, y_train.values.ravel()\n",
    "#ripper_clf: See the model's explanations in RIPPER cells \n",
    "#knn: grid_search_knn.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "#dt_clf: grid_search.best_estimator_.fit(X_train,y_train.values.ravel())\n",
    "#MLP: clf.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "#svm_clf: rnd_search_svm.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "#rnd_search_nb.best_estimator_: rnd_search_nb.best_estimator_.fit(X_train, y_train.values.ravel()) \n",
    "#rnd_search_SGD.best_estimator_: rnd_search_SGD.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "#rnd_search_LR.best_estimator_: rnd_search_LR.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "#rnd_search_XG.best_estimator_:  rnd_search_XG.best_estimator_.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "explainer = ClassifierExplainer(rnd_search_svm.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "InlineExplainer(explainer).shap.contributions_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "#Shap values for each observation in the test dataset\n",
    "shap_values = explainer.get_shap_values_df(1)\n",
    "\n",
    "#Calculate the correct explanations\n",
    "correct_explanations = 0\n",
    "correct_explanations_TWF = 0\n",
    "correct_explanations_HDF = 0\n",
    "correct_explanations_PWF = 0\n",
    "correct_explanations_OSF = 0\n",
    "\n",
    "for k in range(0,len(true_positive_observations)):\n",
    "    #if the failure mode is TWF\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "        #if tool wear is the most important feature\n",
    "        if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "            correct_explanations = correct_explanations+1;\n",
    "            correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "    \n",
    "    #if the failure mode is HDF\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "        maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "        maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "        if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "            correct_explanations = correct_explanations+1;\n",
    "            correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "    #if the failure mode is PWF\n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "        maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "        maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "        if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "            correct_explanations = correct_explanations+1;\n",
    "            correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "    #if the failure mode is OSF        \n",
    "    if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "        maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "        maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "        if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "            correct_explanations = correct_explanations+1;\n",
    "            correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "\n",
    "print(\"TWF: %.4f success, HDF: %.4f success, PWF: %.4f success, OSF: %.4f success \\n\\n\" % (correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions,correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions,correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions,correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions))\n",
    "\n",
    "average_success = ((correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)+(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)+(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)+(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions))/4\n",
    "\n",
    "print(\"Through the model, %d correct explanations are made in the true positive predictions with average success: %.4f \\n\\n\" % (correct_explanations, average_success))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the evaluation metrics for all folds of the best estimators  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_ebm = []\n",
    "auc_folds_best_estimator_ebm = []\n",
    "kappa_folds_best_estimator_ebm = []\n",
    "twf_folds_best_estimator_ebm = []\n",
    "hdf_folds_best_estimator_ebm = []\n",
    "pwf_folds_best_estimator_ebm = []\n",
    "osf_folds_best_estimator_ebm = []\n",
    "av_folds_best_estimator_ebm = []\n",
    "fold_list_ebm = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    display(\"Fold #\"+str(fold))\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    ebm.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_ebm = ebm.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_ebm = accuracy_score(y_test,  y_test_pred_ebm)\n",
    "    cohen_score_ebm = cohen_kappa_score(y_test,  y_test_pred_ebm)\n",
    "    auc_ebm = metrics.roc_auc_score(y_test, y_test_pred_ebm)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_ebm[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_ebm.append(accuracy_ebm)\n",
    "        kappa_folds_best_estimator_ebm.append(cohen_score_ebm)\n",
    "        auc_folds_best_estimator_ebm.append(auc_ebm)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Global Explanations\n",
    "        ebm_global = ebm.explain_global()\n",
    "        show(ebm_global)\n",
    "        \n",
    "        #Local Explanations\n",
    "        \n",
    "        importances_for_all_features_and_their_combinations = ebm.predict_and_contrib(X_test, output='labels')\n",
    "        \n",
    "        local_importance_ebm = []\n",
    "        for deigma in range(0,len(X_test)):\n",
    "            local_importance_ebm.append(importances_for_all_features_and_their_combinations[1][deigma][0:6])\n",
    "        \n",
    "        local_importance_ebm = [abs(x) for x in local_importance_ebm]\n",
    "        \n",
    "        shap_values = pd.DataFrame(local_importance_ebm, columns = X_train.columns)\n",
    "                  \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "            \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_ebm.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_ebm.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_ebm.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_ebm.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_ebm.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_ebm.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_ebm.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_ebm.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_ebm.append(average_success)\n",
    "        fold_list_ebm.append(fold)\n",
    "\n",
    "\n",
    "result_df_best_estimator_ebm = pd.DataFrame({'Accuracy': acc_folds_best_estimator_ebm, 'AUC': auc_folds_best_estimator_ebm, 'Kappa':kappa_folds_best_estimator_ebm, 'TWF':twf_folds_best_estimator_ebm, 'HDF':hdf_folds_best_estimator_ebm, 'PWF':pwf_folds_best_estimator_ebm, 'OSF':osf_folds_best_estimator_ebm, 'Average Success':av_folds_best_estimator_ebm, 'Folds':fold_list_ebm})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_ebm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_lgmbc = []\n",
    "auc_folds_best_estimator_lgmbc = []\n",
    "kappa_folds_best_estimator_lgmbc = []\n",
    "twf_folds_best_estimator_lgmbc = []\n",
    "hdf_folds_best_estimator_lgmbc = []\n",
    "pwf_folds_best_estimator_lgmbc = []\n",
    "osf_folds_best_estimator_lgmbc = []\n",
    "av_folds_best_estimator_lgmbc = []\n",
    "fold_list_lgmbc = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    grid_search_lgbmc_clf.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_lgbmc = grid_search_lgbmc_clf.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_lgbmc = accuracy_score(y_test, y_test_pred_lgbmc)\n",
    "    cohen_score_lgbmc = cohen_kappa_score(y_test, y_test_pred_lgbmc)\n",
    "    auc_lgbmc = metrics.roc_auc_score(y_test, y_test_pred_lgbmc)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_lgbmc[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_lgmbc.append(accuracy_lgbmc)\n",
    "        kappa_folds_best_estimator_lgmbc.append(cohen_score_lgbmc)\n",
    "        auc_folds_best_estimator_lgmbc.append(auc_lgbmc)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(grid_search_lgbmc_clf.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_lgmbc.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_lgmbc.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_lgmbc.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_lgmbc.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_lgmbc.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_lgmbc.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_lgmbc.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_lgmbc.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_lgmbc.append(average_success)\n",
    "        fold_list_lgmbc.append(fold)\n",
    "\n",
    "result_df_best_estimator_lgmbc = pd.DataFrame({'Accuracy': acc_folds_best_estimator_lgmbc, 'AUC': auc_folds_best_estimator_lgmbc, 'Kappa':kappa_folds_best_estimator_lgmbc, 'TWF':twf_folds_best_estimator_lgmbc, 'HDF':hdf_folds_best_estimator_lgmbc, 'PWF':pwf_folds_best_estimator_lgmbc, 'OSF':osf_folds_best_estimator_lgmbc, 'Average Success':av_folds_best_estimator_lgmbc, 'Folds':fold_list_lgmbc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_lgmbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour (KNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_knn = []\n",
    "auc_folds_best_estimator_knn = []\n",
    "kappa_folds_best_estimator_knn = []\n",
    "twf_folds_best_estimator_knn = []\n",
    "hdf_folds_best_estimator_knn = []\n",
    "pwf_folds_best_estimator_knn = []\n",
    "osf_folds_best_estimator_knn = []\n",
    "av_folds_best_estimator_knn = []\n",
    "fold_list_knn = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    grid_search_knn.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_knn = grid_search_knn.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "    cohen_score_knn = cohen_kappa_score(y_test, y_test_pred_knn)\n",
    "    auc_knn = metrics.roc_auc_score(y_test, y_test_pred_knn)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_knn[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_knn.append(accuracy_knn)\n",
    "        kappa_folds_best_estimator_knn.append(cohen_score_knn)\n",
    "        auc_folds_best_estimator_knn.append(auc_knn)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(grid_search_knn.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_knn.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_knn.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_knn.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_knn.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_knn.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_knn.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_knn.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_knn.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_knn.append(average_success)\n",
    "        fold_list_knn.append(fold)\n",
    "\n",
    "result_df_best_estimator_knn = pd.DataFrame({'Accuracy': acc_folds_best_estimator_knn, 'AUC': auc_folds_best_estimator_knn, 'Kappa':kappa_folds_best_estimator_knn, 'TWF':twf_folds_best_estimator_knn, 'HDF':hdf_folds_best_estimator_knn, 'PWF':pwf_folds_best_estimator_knn, 'OSF':osf_folds_best_estimator_knn, 'Average Success':av_folds_best_estimator_knn, 'Folds':fold_list_knn})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_dt = []\n",
    "auc_folds_best_estimator_dt = []\n",
    "kappa_folds_best_estimator_dt = []\n",
    "twf_folds_best_estimator_dt = []\n",
    "hdf_folds_best_estimator_dt = []\n",
    "pwf_folds_best_estimator_dt = []\n",
    "osf_folds_best_estimator_dt = []\n",
    "av_folds_best_estimator_dt = []\n",
    "fold_list_dt = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    grid_search.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_dt = grid_search.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "    cohen_score_dt = cohen_kappa_score(y_test, y_test_pred_dt)\n",
    "    auc_dt = metrics.roc_auc_score(y_test, y_test_pred_dt)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_dt[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_dt.append(accuracy_dt)\n",
    "        kappa_folds_best_estimator_dt.append(cohen_score_dt)\n",
    "        auc_folds_best_estimator_dt.append(auc_dt)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(grid_search.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_dt.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_dt.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_dt.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_dt.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_dt.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_dt.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_dt.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_dt.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_dt.append(average_success)\n",
    "        fold_list_dt.append(fold)\n",
    "\n",
    "result_df_best_estimator_dt = pd.DataFrame({'Accuracy': acc_folds_best_estimator_dt, 'AUC': auc_folds_best_estimator_dt, 'Kappa':kappa_folds_best_estimator_dt, 'TWF':twf_folds_best_estimator_dt, 'HDF':hdf_folds_best_estimator_dt, 'PWF':pwf_folds_best_estimator_dt, 'OSF':osf_folds_best_estimator_dt, 'Average Success':av_folds_best_estimator_dt, 'Folds':fold_list_dt})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_mlp = []\n",
    "auc_folds_best_estimator_mlp = []\n",
    "kappa_folds_best_estimator_mlp = []\n",
    "twf_folds_best_estimator_mlp = []\n",
    "hdf_folds_best_estimator_mlp = []\n",
    "pwf_folds_best_estimator_mlp = []\n",
    "osf_folds_best_estimator_mlp = []\n",
    "av_folds_best_estimator_mlp = []\n",
    "fold_list_mlp = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    clf.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_mlp_clf = clf.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_mlp = accuracy_score(y_test, y_test_pred_mlp_clf)\n",
    "    cohen_score_mlp = cohen_kappa_score(y_test, y_test_pred_mlp_clf)\n",
    "    auc_mlp = metrics.roc_auc_score(y_test, y_test_pred_mlp_clf)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_mlp_clf[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_mlp.append(accuracy_mlp)\n",
    "        kappa_folds_best_estimator_mlp.append(cohen_score_mlp)\n",
    "        auc_folds_best_estimator_mlp.append(auc_mlp)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(clf.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_mlp.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_mlp.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_mlp.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_mlp.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_mlp.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_mlp.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_mlp.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_mlp.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_mlp.append(average_success)\n",
    "        fold_list_mlp.append(fold)\n",
    "\n",
    "result_df_best_estimator_mlp = pd.DataFrame({'Accuracy': acc_folds_best_estimator_mlp, 'AUC': auc_folds_best_estimator_mlp, 'Kappa':kappa_folds_best_estimator_mlp, 'TWF':twf_folds_best_estimator_mlp, 'HDF':hdf_folds_best_estimator_mlp, 'PWF':pwf_folds_best_estimator_mlp, 'OSF':osf_folds_best_estimator_mlp, 'Average Success':av_folds_best_estimator_mlp, 'Folds':fold_list_mlp})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_svm = []\n",
    "auc_folds_best_estimator_svm = []\n",
    "kappa_folds_best_estimator_svm = []\n",
    "twf_folds_best_estimator_svm = []\n",
    "hdf_folds_best_estimator_svm = []\n",
    "pwf_folds_best_estimator_svm = []\n",
    "osf_folds_best_estimator_svm = []\n",
    "av_folds_best_estimator_svm = []\n",
    "fold_list_svm = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    rnd_search_svm.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_svm = rnd_search_svm.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_svm = accuracy_score(y_test, y_test_pred_svm)\n",
    "    cohen_score_svm = cohen_kappa_score(y_test, y_test_pred_svm)\n",
    "    auc_svm = metrics.roc_auc_score(y_test, y_test_pred_svm)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_svm[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_svm.append(accuracy_svm)\n",
    "        kappa_folds_best_estimator_svm.append(cohen_score_svm)\n",
    "        auc_folds_best_estimator_svm.append(auc_svm)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(rnd_search_svm.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_svm.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_svm.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_svm.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_svm.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_svm.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_svm.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_svm.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_svm.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_svm.append(average_success)\n",
    "        fold_list_svm.append(fold)\n",
    "\n",
    "result_df_best_estimator_svm = pd.DataFrame({'Accuracy': acc_folds_best_estimator_svm, 'AUC': auc_folds_best_estimator_svm, 'Kappa':kappa_folds_best_estimator_svm, 'TWF':twf_folds_best_estimator_svm, 'HDF':hdf_folds_best_estimator_svm, 'PWF':pwf_folds_best_estimator_svm, 'OSF':osf_folds_best_estimator_svm, 'Average Success':av_folds_best_estimator_svm, 'Folds':fold_list_svm})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_nb = []\n",
    "auc_folds_best_estimator_nb = []\n",
    "kappa_folds_best_estimator_nb = []\n",
    "twf_folds_best_estimator_nb = []\n",
    "hdf_folds_best_estimator_nb = []\n",
    "pwf_folds_best_estimator_nb = []\n",
    "osf_folds_best_estimator_nb = []\n",
    "av_folds_best_estimator_nb = []\n",
    "fold_list_nb = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    rnd_search_nb.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_nb = rnd_search_nb.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_nb = accuracy_score(y_test, y_test_pred_nb)\n",
    "    cohen_score_nb = cohen_kappa_score(y_test, y_test_pred_nb)\n",
    "    auc_nb = metrics.roc_auc_score(y_test, y_test_pred_nb)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_nb[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_nb.append(accuracy_nb)\n",
    "        kappa_folds_best_estimator_nb.append(cohen_score_nb)\n",
    "        auc_folds_best_estimator_nb.append(auc_nb)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(rnd_search_nb.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_nb.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_nb.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_nb.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_nb.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_nb.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_nb.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_nb.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_nb.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_nb.append(average_success)\n",
    "        fold_list_nb.append(fold)\n",
    "\n",
    "result_df_best_estimator_nb = pd.DataFrame({'Accuracy': acc_folds_best_estimator_nb, 'AUC': auc_folds_best_estimator_nb, 'Kappa':kappa_folds_best_estimator_nb, 'TWF':twf_folds_best_estimator_nb, 'HDF':hdf_folds_best_estimator_nb, 'PWF':pwf_folds_best_estimator_nb, 'OSF':osf_folds_best_estimator_nb, 'Average Success':av_folds_best_estimator_nb, 'Folds':fold_list_nb})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df_best_estimator_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "acc_folds_best_estimator_sgd = []\n",
    "auc_folds_best_estimator_sgd = []\n",
    "kappa_folds_best_estimator_sgd = []\n",
    "twf_folds_best_estimator_sgd = []\n",
    "hdf_folds_best_estimator_sgd = []\n",
    "pwf_folds_best_estimator_sgd = []\n",
    "osf_folds_best_estimator_sgd = []\n",
    "av_folds_best_estimator_sgd = []\n",
    "fold_list_sgd = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    rnd_search_SGD.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_sgd = rnd_search_SGD.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_sgd = accuracy_score(y_test, y_test_pred_sgd)\n",
    "    cohen_score_sgd = cohen_kappa_score(y_test, y_test_pred_sgd)\n",
    "    auc_sgd = metrics.roc_auc_score(y_test, y_test_pred_sgd)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_sgd[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_sgd.append(accuracy_sgd)\n",
    "        kappa_folds_best_estimator_sgd.append(cohen_score_sgd)\n",
    "        auc_folds_best_estimator_sgd.append(auc_sgd)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        \n",
    "        sub_sampled_train_data = shap.sample(X_train, 600, random_state=0) # use 600 samples of train data as background data to make things faster\n",
    "        \n",
    "        explainer = shap.KernelExplainer(rnd_search_SGD.best_estimator_.predict, sub_sampled_train_data)\n",
    "        #explainer = ClassifierExplainer(rnd_search_SGD.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "        \n",
    "        # Calculates the SHAP values - It takes some time\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        feature_names = X_train.columns\n",
    "        result_shap_values = pd.DataFrame(shap_values, columns = feature_names)\n",
    "        \n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        #shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if result_shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(result_shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(result_shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(result_shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(result_shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (result_shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (result_shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (result_shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (result_shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(result_shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(result_shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(result_shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (result_shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (result_shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (result_shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (result_shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(result_shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(result_shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(result_shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (result_shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (result_shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (result_shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (result_shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_sgd.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_sgd.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_sgd.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_sgd.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_sgd.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_sgd.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_sgd.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_sgd.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_sgd.append(average_success)\n",
    "        fold_list_sgd.append(fold)\n",
    "\n",
    "result_df_best_estimator_sgd = pd.DataFrame({'Accuracy': acc_folds_best_estimator_sgd, 'AUC': auc_folds_best_estimator_sgd, 'Kappa':kappa_folds_best_estimator_sgd, 'TWF':twf_folds_best_estimator_sgd, 'HDF':hdf_folds_best_estimator_sgd, 'PWF':pwf_folds_best_estimator_sgd, 'OSF':osf_folds_best_estimator_sgd, 'Average Success':av_folds_best_estimator_sgd, 'Folds':fold_list_sgd})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapley values for linear models are equal to \"model weight * feature value\", where feature values are normalized and model weights are trained with the normalized feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_log = []\n",
    "auc_folds_best_estimator_log = []\n",
    "kappa_folds_best_estimator_log = []\n",
    "twf_folds_best_estimator_log = []\n",
    "hdf_folds_best_estimator_log = []\n",
    "pwf_folds_best_estimator_log = []\n",
    "osf_folds_best_estimator_log = []\n",
    "av_folds_best_estimator_log = []\n",
    "fold_list_log = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    display(\"Fold #\"+str(fold))\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    rnd_search_LR.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_log = rnd_search_LR.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_log = accuracy_score(y_test, y_test_pred_log)\n",
    "    cohen_score_log = cohen_kappa_score(y_test, y_test_pred_log)\n",
    "    auc_log = metrics.roc_auc_score(y_test, y_test_pred_log)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_log[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_log.append(accuracy_log)\n",
    "        kappa_folds_best_estimator_log.append(cohen_score_log)\n",
    "        auc_folds_best_estimator_log.append(auc_log)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Global explainability\n",
    "        \n",
    "        # Get importance of each feature\n",
    "        w0 = rnd_search_LR.best_estimator_.intercept_[0]\n",
    "        w = w1, w2, w3, w4, w5, w6 = rnd_search_LR.best_estimator_.coef_[0]\n",
    "\n",
    "        feature_names = X_train.columns\n",
    "\n",
    "        feature_importance = pd.DataFrame(feature_names, columns = [\"feature\"])\n",
    "        feature_importance[\"importance\"] = pow(math.e,w)\n",
    "        feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending = False)\n",
    "        display(feature_importance)\n",
    "        \n",
    "      \n",
    "        # Get importance of each feature\n",
    "        importance = rnd_search_LR.best_estimator_.coef_[0]\n",
    "\n",
    "        #Feature importances for linear models are equal to \"model weight * feature value\", where feature values are normalized and model weights are trained with the normalized feature values.\n",
    "        local_importance = np.multiply(importance, X_test.to_numpy())\n",
    "          \n",
    "        shap_values = pd.DataFrame(local_importance, columns = X_train.columns)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_log.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_log.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_log.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_log.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_log.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_log.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_log.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_log.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_log.append(average_success)\n",
    "        fold_list_log.append(fold)\n",
    "\n",
    "result_df_best_estimator_log = pd.DataFrame({'Accuracy': acc_folds_best_estimator_log, 'AUC': auc_folds_best_estimator_log, 'Kappa':kappa_folds_best_estimator_log, 'TWF':twf_folds_best_estimator_log, 'HDF':hdf_folds_best_estimator_log, 'PWF':pwf_folds_best_estimator_log, 'OSF':osf_folds_best_estimator_log, 'Average Success':av_folds_best_estimator_log, 'Folds':fold_list_log})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_xgb = []\n",
    "auc_folds_best_estimator_xgb = []\n",
    "kappa_folds_best_estimator_xgb = []\n",
    "twf_folds_best_estimator_xgb = []\n",
    "hdf_folds_best_estimator_xgb = []\n",
    "pwf_folds_best_estimator_xgb = []\n",
    "osf_folds_best_estimator_xgb = []\n",
    "av_folds_best_estimator_xgb = []\n",
    "fold_list_xgb = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    X_train.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]\n",
    "    X_test.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test.columns.values]\n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    rnd_search_XG.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_xgb = rnd_search_XG.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb)\n",
    "    cohen_score_xgb = cohen_kappa_score(y_test, y_test_pred_xgb)\n",
    "    auc_xgb = metrics.roc_auc_score(y_test, y_test_pred_xgb)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_xgb[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_xgb.append(accuracy_xgb)\n",
    "        kappa_folds_best_estimator_xgb.append(cohen_score_xgb)\n",
    "        auc_folds_best_estimator_xgb.append(auc_xgb)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "        \n",
    "        #Local Explanations\n",
    "        explainer = ClassifierExplainer(rnd_search_XG.best_estimator_.fit(X_train, y_train.values.ravel()), X_test, y_test)\n",
    "        \n",
    "        # load JS visualization code to notebook\n",
    "        shap.initjs()\n",
    "\n",
    "        #Shap values for each observation in the test dataset\n",
    "        shap_values = explainer.get_shap_values_df(1)\n",
    "          \n",
    "        #Calculate the correct explanations\n",
    "        correct_explanations = 0\n",
    "        correct_explanations_TWF = 0\n",
    "        correct_explanations_HDF = 0\n",
    "        correct_explanations_PWF = 0\n",
    "        correct_explanations_OSF = 0\n",
    "\n",
    "        for k in range(0,len(true_positive_observations)):\n",
    "            #if the failure mode is TWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1:\n",
    "                #if tool wear is the most important feature\n",
    "                if shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == max(shap_values.loc[true_positive_indexes[k],:]):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_TWF = correct_explanations_TWF + 1;\n",
    "                \n",
    "            #if the failure mode is HDF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"AirtemperatureK\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"ProcesstemperatureK\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_HDF = correct_explanations_HDF + 1;\n",
    "            \n",
    "            \n",
    "            #if the failure mode is PWF\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: \n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Rotationalspeedrpm\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_PWF = correct_explanations_PWF + 1;\n",
    "            \n",
    "            #if the failure mode is OSF        \n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1:\n",
    "                maximum1 = max(shap_values.loc[true_positive_indexes[k],:]) \n",
    "                maximum2 = max(shap_values.loc[true_positive_indexes[k],:], key = lambda x: min(shap_values.loc[true_positive_indexes[k],:])-1 if (x == maximum1) else x)\n",
    "                if (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"Toolwearmin\"] == maximum2) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum1) or (shap_values.loc[true_positive_indexes[k],\"TorqueNm\"] == maximum2):\n",
    "                    correct_explanations = correct_explanations+1;\n",
    "                    correct_explanations_OSF = correct_explanations_OSF + 1;\n",
    "        \n",
    "        denominator = 0\n",
    "        \n",
    "        if number_of_TWF_failures_in_true_positive_predictions != 0:\n",
    "            twf_folds_best_estimator_xgb.append(correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions)\n",
    "            twf_success = correct_explanations_TWF/number_of_TWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            twf_folds_best_estimator_xgb.append(correct_explanations_TWF)\n",
    "            twf_success = 0\n",
    "        if number_of_HDF_failures_in_true_positive_predictions != 0:\n",
    "            hdf_folds_best_estimator_xgb.append(correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions)\n",
    "            hdf_success = correct_explanations_HDF/number_of_HDF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            hdf_folds_best_estimator_xgb.append(correct_explanations_HDF)\n",
    "            hdf_success = 0\n",
    "        if number_of_PWF_failures_in_true_positive_predictions != 0:\n",
    "            pwf_folds_best_estimator_xgb.append(correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions)\n",
    "            pwf_success = correct_explanations_PWF/number_of_PWF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            pwf_folds_best_estimator_xgb.append(correct_explanations_PWF)\n",
    "            pwf_success = 0\n",
    "        if number_of_OSF_failures_in_true_positive_predictions != 0:\n",
    "            osf_folds_best_estimator_xgb.append(correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions)\n",
    "            osf_success = correct_explanations_OSF/number_of_OSF_failures_in_true_positive_predictions\n",
    "            denominator = denominator + 1\n",
    "        else:\n",
    "            osf_folds_best_estimator_xgb.append(correct_explanations_OSF)\n",
    "            osf_success = 0\n",
    "    \n",
    "        average_success = (twf_success+hdf_success+pwf_success+osf_success)/denominator\n",
    "        av_folds_best_estimator_xgb.append(average_success)\n",
    "        fold_list_xgb.append(fold)\n",
    "\n",
    "result_df_best_estimator_xgb = pd.DataFrame({'Accuracy': acc_folds_best_estimator_xgb, 'AUC': auc_folds_best_estimator_xgb, 'Kappa':kappa_folds_best_estimator_xgb, 'TWF':twf_folds_best_estimator_xgb, 'HDF':hdf_folds_best_estimator_xgb, 'PWF':pwf_folds_best_estimator_xgb, 'OSF':osf_folds_best_estimator_xgb, 'Average Success':av_folds_best_estimator_xgb, 'Folds':fold_list_xgb})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_best_estimator_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIPPER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_folds_best_estimator_ripper = []\n",
    "auc_folds_best_estimator_ripper = []\n",
    "kappa_folds_best_estimator_ripper = []\n",
    "twf_folds_best_estimator_ripper = []\n",
    "hdf_folds_best_estimator_ripper = []\n",
    "pwf_folds_best_estimator_ripper = []\n",
    "osf_folds_best_estimator_ripper = []\n",
    "av_folds_best_estimator_ripper = []\n",
    "fold_list_ripper = []\n",
    "\n",
    "\n",
    "for fold in range(1,11):\n",
    "    \n",
    "    display(\"Fold #\"+str(fold))\n",
    "    \n",
    "    #Dataset for each fold\n",
    "    ai4i2020_encoded_balanced = ai4i2020_encoded_balanced.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\X_train_iter_\" + str(fold) + \".csv\")\n",
    "    original_X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\X_test_iter_\" + str(fold) + \".csv\")\n",
    "\n",
    "    X_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_train = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "    X_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "    y_test = pd.read_csv('..\\\\..\\\\dataset\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    original_X_train = original_X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_X_test = original_X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_train = y_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    y_test = y_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    X_train.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]\n",
    "    X_test.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test.columns.values]\n",
    "    \n",
    "    #Build the Classifier\n",
    "    \n",
    "    grid_ripper.best_estimator_.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predictions for the test set\n",
    "    y_test_pred_ripper = grid_ripper.best_estimator_.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Evaluation metrics for the test dataset\n",
    "    accuracy_ripper = grid_ripper.best_estimator_.score(X_test,  y_test.values.ravel())\n",
    "    cohen_score_ripper = cohen_kappa_score(y_test, y_test_pred_ripper)\n",
    "    auc_ripper = metrics.roc_auc_score(y_test, y_test_pred_ripper)\n",
    "    \n",
    "    \n",
    "    #Find the observations' indexes that the model correctly predicted as faulty\n",
    "    true_positive_indexes = []\n",
    "    i=1;\n",
    "\n",
    "    #According to the chosen model\n",
    "    #For example, y_test_pred_lgbmc for LGBM Classifier\n",
    "    for k in range(0,len(y_test)):\n",
    "        if (y_test.loc[k,'Machinefailure']==int(y_test_pred_ripper[k])) and (y_test.loc[k,'Machinefailure']==1):\n",
    "            true_positive_indexes.append(k)\n",
    "            i=i+1;\n",
    "\n",
    "    #Find the observations that the selected model correctly predicted as faulty based on the previous indexes\n",
    "    true_positive_observations = pd.DataFrame()\n",
    "    for k in range(0,len(true_positive_indexes)):\n",
    "        new_row = pd.concat([original_X_test.loc[true_positive_indexes[k],:],y_test.loc[true_positive_indexes[k],:]], axis=0)\n",
    "        true_positive_observations = true_positive_observations.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if not true_positive_observations.empty:\n",
    "        \n",
    "        #Append in lists\n",
    "        acc_folds_best_estimator_ripper.append(accuracy_ripper)\n",
    "        kappa_folds_best_estimator_ripper.append(cohen_score_ripper)\n",
    "        auc_folds_best_estimator_ripper.append(auc_ripper)\n",
    "        \n",
    "    \n",
    "        true_positive_observations_with_failure_modes = pd.DataFrame()\n",
    "        true_positive_observations_with_failure_modes = ai4i2020_encoded_balanced.join(true_positive_observations.set_index(['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure']), ['Type', 'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'Machinefailure'], how='right')       \n",
    "        final_true_positive_observations_with_failure_modes = true_positive_observations_with_failure_modes.reset_index(drop=True)\n",
    "    \n",
    "        #display(\"Number of true positive predictions: \" + str(len(final_true_positive_observations_with_failure_modes)))\n",
    "\n",
    "        number_of_TWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_HDF_failures_in_true_positive_predictions = 0\n",
    "        number_of_PWF_failures_in_true_positive_predictions = 0\n",
    "        number_of_OSF_failures_in_true_positive_predictions = 0\n",
    "        number_of_random_failures_in_true_positive_predictions=0\n",
    "\n",
    "        for k in range(0,len(final_true_positive_observations_with_failure_modes)):\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==1: #if the failure mode is TWF\n",
    "                number_of_TWF_failures_in_true_positive_predictions = number_of_TWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==1: #if the failure mode is HDF\n",
    "                number_of_HDF_failures_in_true_positive_predictions = number_of_HDF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==1: #if the failure mode is PWF\n",
    "                number_of_PWF_failures_in_true_positive_predictions = number_of_PWF_failures_in_true_positive_predictions + 1;\n",
    "            if final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==1: #if the failure mode is OSF\n",
    "                number_of_OSF_failures_in_true_positive_predictions = number_of_OSF_failures_in_true_positive_predictions + 1;\n",
    "            if (final_true_positive_observations_with_failure_modes.loc[k,\"Machinefailure\"]==1) and (final_true_positive_observations_with_failure_modes.loc[k,\"TWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"HDF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"PWF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"OSF\"]==0) and (final_true_positive_observations_with_failure_modes.loc[k,\"RNF\"]==0):\n",
    "                number_of_random_failures_in_true_positive_predictions = number_of_random_failures_in_true_positive_predictions+1;\n",
    "\n",
    "result_df_best_estimator_ripper = pd.DataFrame({'Accuracy': acc_folds_best_estimator_ripper, 'AUC': auc_folds_best_estimator_ripper, 'Kappa':kappa_folds_best_estimator_ripper})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df_best_estimator_ripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
