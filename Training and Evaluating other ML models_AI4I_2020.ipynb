{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_friedman3, make_s_curve\n",
    "from sklearn.linear_model import BayesianRidge, ElasticNet\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# for Box-Cox Transformation\n",
    "from scipy import stats\n",
    "\n",
    "# plotting modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "#Multilabel Stratified K Fold Creation\n",
    "#pip install iterative-stratification\n",
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in local\n",
    "# Fold index\n",
    "fold = 1\n",
    "\n",
    "X_train = pd.read_csv('G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\Scaled_X_train_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "y_train = pd.read_csv('G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_iter_\" + str(fold) + \".csv\")\n",
    "X_test = pd.read_csv('G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\Scaled_X_test_iter_\" + str(fold) + \".csv\", names=['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "y_test = pd.read_csv('G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_iter_\" + str(fold) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "auc_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Cognitive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "y_train_pred_fcm = genfromtxt(r'G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\y_train_pred_fcm.csv\", delimiter=',')\n",
    "y_test_pred_fcm = genfromtxt(r'G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\y_test_pred_fcm.csv\", delimiter=',')\n",
    "fcm_pred_class_train = genfromtxt(r'G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Training Dataset\" + \"\\\\fcm_pred_class_train.csv\", delimiter=',')\n",
    "fcm_pred_class_test = genfromtxt(r'G:\\\\.shortcut-targets-by-id\\\\1-wapAl6N5YrCs68c4NiFKyvybXTXmdgZ\\\\Ph_D_Tyrovolas\\\\Our Papers\\\\3rd_Paper-Proposal\\\\Testbed Codes\\\\AI4I_Case_Study\\\\k-fold cross validation datasets\\\\' + str(fold) + \"\\\\Test Dataset\" + \"\\\\fcm_pred_class_test.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, fcm_pred_class_train)\n",
    "sns.heatmap(confusion_matrix(y_train, fcm_pred_class_train), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [15756, 1751]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2a10832fa869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision Score: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfcm_pred_class_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall Score: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcm_pred_class_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 Score: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcm_pred_class_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m     \"\"\"\n\u001b[1;32m-> 1776\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1777\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    388\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15756, 1751]"
     ]
    }
   ],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,fcm_pred_class_train))\n",
    "print(\"Recall Score: \",recall_score(y_train, fcm_pred_class_train))\n",
    "print(\"F1 Score: \",f1_score(y_train, fcm_pred_class_train))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, fcm_pred_class_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, fcm_pred_class_test))\n",
    "print(\"Recall Score: \",recall_score(y_test, fcm_pred_class_test))\n",
    "print(\"F1 Score: \",f1_score(y_test, fcm_pred_class_test))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, fcm_pred_class_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate AUC of model\n",
    "from sklearn import metrics\n",
    "auc_fcm = metrics.roc_auc_score(y_test, y_test_pred_fcm)\n",
    "print(auc_fcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(metrics.accuracy_score(y_test, Predicted_classes))\n",
    "auc_list.append(auc_fcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dt_clf = dt_clf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_dt = dt_clf.predict(X_train)\n",
    "\n",
    "print(\"Decision Tree score: \",dt_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_dt)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_dt), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train,y_train_pred_dt))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_dt))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_dt))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_dt))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_dt))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_dt))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_dt = metrics.roc_auc_score(y_test, y_test_pred_dt)\n",
    "print(auc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_dt))\n",
    "auc_list.append(auc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# for modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build a model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='Adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = EarlyStopping(monitor='val_accuracy', \n",
    "                                   mode='max', # don't minimize the accuracy!\n",
    "                                   patience=10,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "# now we just update our model fit call\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=80, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_ann = model.predict(X_train)\n",
    "\n",
    "print(\"Artificial Neural Network score: \",model.evaluate(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dict = history.history\n",
    "# Learning curve(Loss)\n",
    "# let's see the training and validation loss by epoch\n",
    "\n",
    "# loss\n",
    "loss_values = history_dict['loss'] # you can change this\n",
    "val_loss_values = history_dict['val_loss'] # you can also change this\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(loss_values) + 1) \n",
    "\n",
    "# plot\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learning curve(accuracy)\n",
    "# let's see the training and validation accuracy by epoch\n",
    "\n",
    "# accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# orange is for \"orange\"\n",
    "plt.plot(epochs, val_acc, 'orange', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# this is the max value - should correspond to\n",
    "# the HIGHEST train accuracy\n",
    "np.max(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# see how these are numbers between 0 and 1? \n",
    "model.predict(X_train) # prob of successes (survival)\n",
    "np.round(model.predict(X_train),0) # 1 and 0 (survival or not)\n",
    "y_train # 1 and 0 (survival or not)\n",
    "\n",
    "# so we need to round to a whole number (0 or 1),\n",
    "# or the confusion matrix won't work!\n",
    "preds = np.round(model.predict(X_train),0)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_train, preds)) # order matters! (actual, predicted)\n",
    "\n",
    "print(classification_report(y_train, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how these are numbers between 0 and 1? \n",
    "model.predict(X_test) # prob of successes (survival)\n",
    "np.round(model.predict(X_test),0) # 1 and 0 (survival or not)\n",
    "y_test # 1 and 0 (survival or not)\n",
    "\n",
    "# so we need to round to a whole number (0 or 1),\n",
    "# or the confusion matrix won't work!\n",
    "preds = np.round(model.predict(X_test),0)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, preds)) # order matters! (actual, predicted)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate AUC of model\n",
    "from sklearn import metrics\n",
    "auc_ann = metrics.roc_auc_score(y_test, model.predict(X_test))\n",
    "print(auc_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(metrics.accuracy_score(y_test, preds))\n",
    "auc_list.append(metrics.roc_auc_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "svm_clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_svm = svm_clf.predict(X_train)\n",
    "\n",
    "print(\"Support Vector Machine score: \",svm_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_svm)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_svm), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_svm))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_svm))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_svm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_svm = svm_clf.predict(X_test)\n",
    "#y_test_pred_sgd = sgd_clf.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_svm))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_svm))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_svm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_svm = metrics.roc_auc_score(y_test, y_test_pred_svm)\n",
    "print(auc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_svm))\n",
    "auc_list.append(auc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_nb = nb_clf.predict(X_train)\n",
    "\n",
    "print(\"Naive Bayes score: \",nb_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_nb)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_nb), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_nb))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_nb))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_nb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "NB_distribution = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "nb_clf = GaussianNB()       \n",
    "\n",
    "rnd_search_nb = RandomizedSearchCV(nb_clf, param_distributions = NB_distribution, random_state = 42) \n",
    "rnd_search_nb.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_nb.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "#y_test_pred_nb = nb_clf.predict(X_test)\n",
    "y_test_pred_nb = rnd_search_nb.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_nb))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_nb))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_nb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate AUC of model\n",
    "from sklearn import metrics\n",
    "auc_nb = metrics.roc_auc_score(y_test, y_test_pred_nb)\n",
    "print(auc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_nb))\n",
    "auc_list.append(auc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_sgd = sgd_clf.predict(X_train)\n",
    "print(\"Stochastic Gradient Descent Classifier score: \",sgd_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred_sgd)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_sgd), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_sgd))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_sgd))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_sgd))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "param_distribs = {\n",
    "        \"average\": [True, False],\n",
    "        \"loss\":['hinge', 'log_loss', 'modified_huber', 'squared_hinge',  'perceptron'],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        \"learning_rate\":['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        \"class_weight\":[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "        \"eta0\":[1, 10, 100],\n",
    "        \"penalty\":['l2', 'l1', 'elasticnet']\n",
    "    }\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "rnd_search_SGD = RandomizedSearchCV(sgd_clf, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "rnd_search_SGD.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_SGD.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_SGD.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_sgd = rnd_search_SGD.best_estimator_.predict(X_test)\n",
    "#y_test_pred_sgd = sgd_clf.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_sgd))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_sgd))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_sgd))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#calculate AUC of model\n",
    "auc_sgd = metrics.roc_auc_score(y_test, y_test_pred_sgd)\n",
    "print(auc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_sgd))\n",
    "auc_list.append(auc_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#logistic regression for targets \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_clf = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=42)\n",
    "log_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_log = log_clf.predict(X_train)\n",
    "print(\"Logistic Regression score: \",log_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confusion_matrix(y_train, y_train_pred_log)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_log), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_log))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_log))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_log))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=42)\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2'],\n",
    "                     solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "rnd_search_LR = RandomizedSearchCV(logistic, distributions, random_state=42)\n",
    "rnd_search_LR.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_LR.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_test_pred_log = rnd_search_LR.best_estimator_.predict(X_test)\n",
    "#y_test_pred_log = log_clf.predict(X_test)\n",
    "\n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_log))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_log))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_log))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_test_pred_log)\n",
    "#calculate AUC of model\n",
    "auc_log = metrics.roc_auc_score(y_test, y_test_pred_log)\n",
    "print(auc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_log))\n",
    "auc_list.append(auc_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "X_train.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "y_train_pred_xgb = xgb_classifier.predict(X_train)\n",
    "print(\"XGBoost score: \",xgb_classifier.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confusion_matrix(y_train, y_train_pred_xgb)\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred_xgb), annot=True,fmt='d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for training dataset\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "print(\"Precision Score: \",precision_score(y_train, y_train_pred_xgb))\n",
    "print(\"Recall Score: \",recall_score(y_train, y_train_pred_xgb))\n",
    "print(\"F1 Score: \",f1_score(y_train, y_train_pred_xgb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "XG_distributions = dict(n_estimators=[100,200,300,400,500,600,700,800, 900, 1000],\n",
    "                     max_depths = [2, 5, 10, 20],\n",
    "                     learning_rate=[0.1,0.15,0.2,0.25,0.3],\n",
    "                     colsample_bytree=[0.5,0.6,0.7,0.8,0.9,1],\n",
    "                     subsample=[0.5,0.6,0.7,0.8,0.9,1],\n",
    "                     grow_policy = ['depthwise', 'lossguide'],\n",
    "                     booster = ['gbtree', 'gblinear', 'dart'],\n",
    "                     sampling_method = ['uniform','gradient_based'])\n",
    "rnd_search_XG = RandomizedSearchCV(xgb_classifier, XG_distributions, random_state=42)\n",
    "rnd_search_XG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = pd.DataFrame(rnd_search_XG.cv_results_).sort_values(by=['rank_test_score'])\n",
    "for mean_score, params,rank in zip(cvres[\"mean_test_score\"], cvres[\"params\"],cvres[\"rank_test_score\"]):\n",
    "    print(\"Rank {}# - Score: {} - {}\".format(rank, np.sqrt(mean_score), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnd_search_XG.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "X_test.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_xgb = rnd_search_XG.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_pred_xgb), annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance measures for test dataset\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score \n",
    "print(\"Precision Score: \",precision_score(y_test, y_test_pred_xgb))\n",
    "print(\"Recall Score: \",recall_score(y_test, y_test_pred_xgb))\n",
    "print(\"F1 Score: \",f1_score(y_test, y_test_pred_xgb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_test_pred_xgb)\n",
    "#calculate AUC of model\n",
    "auc_xgb = metrics.roc_auc_score(y_test, y_test_pred_xgb)\n",
    "print(auc_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.append(accuracy_score(y_test, y_test_pred_xgb))\n",
    "auc_list.append(auc_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw ROC curve and PR curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "fpr_FCM, tpr_FCM, thresholds_FCM = roc_curve(y_train, y_train_pred_fcm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "fpr_DT, tpr_DT, thresholds_DT = roc_curve(y_train, y_train_pred_dt)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Artificial Neural Network\n",
    "fpr_ANN, tpr_ANN, thresholds_ANN = roc_curve(y_train, model.predict(X_train))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "fpr_SVM, tpr_SVM, thresholds_SVM = roc_curve(y_train,  y_train_pred_svm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "fpr_SGD, tpr_SGD, thresholds_SGD = roc_curve(y_train, y_train_pred_sgd)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "fpr_NB, tpr_NB, thresholds_NB = roc_curve(y_train, y_train_pred_nb)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "fpr_LR, tpr_LR, thresholds_LR = roc_curve(y_train, y_train_pred_log)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "fpr_XG, tpr_XG, thresholds_XG = roc_curve(y_train, y_train_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))              \n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "plt.plot(fpr_FCM, tpr_FCM, linewidth=2, label=\"Fuzzy Cognitive Map\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "plt.plot(fpr_DT, tpr_DT, linewidth=2, label=\"Decision Tree\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Artificial Neural Network\n",
    "plt.plot(fpr_ANN, tpr_ANN, linewidth=2, label=\"Artificial Neural Network\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "plt.plot(fpr_SVM, tpr_SVM, linewidth=2, label=\"Support Vector Machine\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "plt.plot(fpr_SGD, tpr_SGD, linewidth=2, label=\"Stochastic Gradient Descent\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "plt.plot(fpr_NB, tpr_NB, \"m-\", linewidth=2, label=\"Gaussian Naive Bayes\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "plt.plot(fpr_LR, tpr_LR, linewidth=2, label=\"Logistic Regression\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "plt.plot(fpr_XG, tpr_XG, linewidth=2, label=\"XGBoost\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# fpr_SGD_90 = fpr_SGD[np.argmax(tpr_SGD >= 0.9)]           \n",
    "\n",
    "# plt.plot([fpr_SGD_90, fpr_SGD_90], [0., 0.9], \"r:\")\n",
    "# plt.plot([0.0, fpr_SGD_90], [0.9, 0.9], \"r:\")  \n",
    "# plt.plot([fpr_SGD_90], [0.9], \"ro\")   \n",
    "\n",
    "# AUC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "fpr_FCM, tpr_FCM, thresholds_FCM = roc_curve(y_test, y_test_pred_fcm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "fpr_DT, tpr_DT, thresholds_DT = roc_curve(y_test, y_test_pred_dt)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Artificial Neural Network\n",
    "fpr_ANN, tpr_ANN, thresholds_ANN = roc_curve(y_test, model.predict(X_test))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "fpr_SVM, tpr_SVM, thresholds_SVM = roc_curve(y_test, y_test_pred_svm)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "fpr_SGD, tpr_SGD, thresholds_SGD = roc_curve(y_test, y_test_pred_sgd)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "fpr_NB, tpr_NB, thresholds_NB = roc_curve(y_test, y_test_pred_nb)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "fpr_LR, tpr_LR, thresholds_LR = roc_curve(y_test, y_test_pred_log)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "fpr_XG, tpr_XG, thresholds_XG = roc_curve(y_test, y_test_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))                                    \n",
    "\n",
    "#Fuzzy Cognitive Map\n",
    "plt.plot(fpr_FCM, tpr_FCM, linewidth=2, label=\"Fuzzy Cognitive Map\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Decision Tree\n",
    "plt.plot(fpr_DT, tpr_DT, linewidth=2, label=\"Decision Tree\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Artificial Neural Network\n",
    "plt.plot(fpr_ANN, tpr_ANN, linewidth=2, label=\"Artificial Neural Network\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Support Vector Machine\n",
    "plt.plot(fpr_SVM, tpr_SVM, linewidth=2, label=\"Support Vector Machine\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "plt.plot(fpr_SGD, tpr_SGD, linewidth=2, label=\"Stochastic Gradient Descent\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "plt.plot(fpr_NB, tpr_NB, \"m-\", linewidth=2, label=\"Gaussian Naive Bayes\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Linear Regresison\n",
    "plt.plot(fpr_LR, tpr_LR, linewidth=2, label=\"Logistic Regression\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# XGBoost\n",
    "plt.plot(fpr_XG, tpr_XG, linewidth=2, label=\"XGBoost\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# fpr_SGD_90 = fpr_SGD[np.argmax(tpr_SGD >= 0.9)]           \n",
    "\n",
    "# plt.plot([fpr_SGD_90, fpr_SGD_90], [0., 0.9], \"r:\")\n",
    "# plt.plot([0.0, fpr_SGD_90], [0.9, 0.9], \"r:\")  \n",
    "# plt.plot([fpr_SGD_90], [0.9], \"ro\")   \n",
    "\n",
    "# AUC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The area under curve (AUC)\n",
    "Through AUC you can summarize the performance of each classifier into a single measure when comparing different classifiers. Calculating the area under the ROC curve, abbreviated as AUC, is a typical method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['Fuzzy Cognitive Map', 'Decision Tree', 'Artificial Neural Network', 'Support Vector Machine', 'Stochastic Gradient Descent', 'Gaussian Naive Bayes', 'Logistic Regression', 'XGBoost']\n",
    "\n",
    "#accuracy and AUC\n",
    "result_df = pd.DataFrame({'Model':model_list, 'Accuracy': acc_list, 'AUC': auc_list})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
